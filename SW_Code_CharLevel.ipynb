{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6116952,"sourceType":"datasetVersion","datasetId":3505809},{"sourceId":6125391,"sourceType":"datasetVersion","datasetId":3511519},{"sourceId":7160860,"sourceType":"datasetVersion","datasetId":4135938},{"sourceId":7163040,"sourceType":"datasetVersion","datasetId":4137539}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Установка и импорт всех необходимых зависимостей","metadata":{"_cell_guid":"07105a38-167d-4080-86f1-e28bbc172b85","_uuid":"b7f3779a-a199-4bcc-b86c-6eba030528bd","trusted":true}},{"cell_type":"code","source":"!pip install -q razdel\n!pip install -q pymorphy2\n!pip install -q git+https://github.com/ahmados/rusynonyms.git\n!pip install -q natasha\n!pip install -q pyaml-env\n!pip install -q captum","metadata":{"_cell_guid":"16d1f1be-6c5b-4cf0-af02-3f589e64f949","_uuid":"4b94f1c3-c161-4222-abfa-e3fb66e4880d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T23:28:48.202293Z","iopub.execute_input":"2023-12-09T23:28:48.203215Z","iopub.status.idle":"2023-12-09T23:30:12.504624Z","shell.execute_reply.started":"2023-12-09T23:28:48.203171Z","shell.execute_reply":"2023-12-09T23:30:12.503253Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nscikit-image 0.21.0 requires networkx>=2.8, but you have networkx 2.6.3 which is incompatible.\nydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport sys\n\npath_to_alti = '/kaggle/input/transformer-contributions1/transformer-contributions'\nif not path_to_alti in sys.path:\n    sys.path.append(path_to_alti)\n\nfrom src.utils_contributions import *\nfrom src.contributions import ModelWrapper, ClassificationModelWrapperCaptum, interpret_sentence, occlusion","metadata":{"execution":{"iopub.status.busy":"2023-12-10T00:04:15.583489Z","iopub.execute_input":"2023-12-10T00:04:15.584116Z","iopub.status.idle":"2023-12-10T00:04:15.589582Z","shell.execute_reply.started":"2023-12-10T00:04:15.584085Z","shell.execute_reply":"2023-12-10T00:04:15.588518Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\nimport pandas as pd\n\nimport nltk\nfrom nltk.corpus import stopwords\nimport re\nimport pymorphy2\nfrom razdel import tokenize\nfrom razdel import sentenize\nimport string\nfrom natasha import (\n    MorphVocab,\n    NewsMorphTagger,\n    NewsEmbedding,\n    Segmenter,\n    NewsSyntaxParser,\n    Doc\n)\n\nimport torch\nimport tensorflow_hub as hub\nfrom torch.utils.data import Dataset, DataLoader\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\nimport numpy as np\nfrom sklearn.metrics import f1_score\n\nfrom tqdm import tqdm\nfrom typing import *\n\nfrom lime.lime_text import LimeTextExplainer\nimport shap\n\nnltk.download('stopwords')\nnltk.download('punkt')\nrus_stopwords = stopwords.words('russian')\npunctuation = list(string.punctuation)","metadata":{"_cell_guid":"e8af1228-dfb5-4d7f-bbf6-d1cb72552c66","_uuid":"11ecb4af-671c-4f65-8913-9c95f7f796bd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-10T00:04:17.280214Z","iopub.execute_input":"2023-12-10T00:04:17.280614Z","iopub.status.idle":"2023-12-10T00:04:17.291416Z","shell.execute_reply.started":"2023-12-10T00:04:17.280582Z","shell.execute_reply":"2023-12-10T00:04:17.290017Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Работа с данными (kaggle)","metadata":{"_cell_guid":"d7cacad4-4f63-43c2-93b1-c9c180bf748d","_uuid":"4351a3ac-2754-4156-96ae-b1866e7f6e82","trusted":true}},{"cell_type":"code","source":"datasets_folder = '/kaggle/input/sw-datasets/Russian-Sentiment-Analysis-Evaluation-Datasets'\ndatasets = ['SentiRuEval-2015-telecoms', 'SentiRuEval-2015-banks', 'SentiRuEval-2016-banks', 'SentiRuEval-2016-telecoms']\nsamples = ['test.xml', 'train.xml', 'test_etalon.xml']","metadata":{"_cell_guid":"19eb260a-7fe2-42e3-ac1e-9657a713481c","_uuid":"5b40ffa6-7032-4f5c-9c17-3cdf66f4a633","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-10T00:04:18.601553Z","iopub.execute_input":"2023-12-10T00:04:18.601920Z","iopub.status.idle":"2023-12-10T00:04:18.606731Z","shell.execute_reply.started":"2023-12-10T00:04:18.601892Z","shell.execute_reply":"2023-12-10T00:04:18.605718Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"def extract_data(path: str) -> pd.DataFrame:\n    \"\"\"\n    функция для извлечения данных из xml\n    \"\"\"\n    tree = ET.parse(path)\n    root = tree.getroot()\n    DataFrame = dict()\n    database = root.findall('database')[0]\n    DataFrame_columns = list()\n\n    for idx, table in enumerate(database.findall('table')):\n        for column in table.findall('column'):\n            DataFrame[column.attrib['name']] = list()\n            DataFrame_columns.append(column.attrib['name'])\n        if idx == 0:\n            break\n\n    for table in database.findall('table'):\n        for column in table.findall('column'):\n            DataFrame[column.attrib['name']].append(column.text)\n\n    data = pd.DataFrame(DataFrame, columns=DataFrame_columns)\n    return data\n\n# инициализация всех путей (kaggle)\nbanks_dataset = datasets[2]\npath2samples = os.path.join(datasets_folder, banks_dataset)\nbanks = ['sberbank', 'vtb', 'gazprom', 'alfabank', 'bankmoskvy', 'raiffeisen', 'uralsib', 'rshb']\n\npath2test = os.path.join(path2samples, samples[2])\ndata_test = extract_data(path2test)\n\npath2train = os.path.join(path2samples, samples[1])\ndata_train = extract_data(path2train)","metadata":{"_cell_guid":"10ad2541-7c34-4b11-a6d4-8ef30594e6e0","_uuid":"77e7298c-cf2e-4be8-a178-de925ce239f3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-10T00:04:19.177656Z","iopub.execute_input":"2023-12-10T00:04:19.178602Z","iopub.status.idle":"2023-12-10T00:04:20.532158Z","shell.execute_reply.started":"2023-12-10T00:04:19.178569Z","shell.execute_reply":"2023-12-10T00:04:20.531109Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"def extract_text_features(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    функция для первичной обработки текста от лишних символов\n    \"\"\"\n    extracted_data = dict()\n    extracted_data['text'] = list()\n    extracted_data['0class'] = list()\n    extracted_data['1class'] = list()\n\n    for idx in range(len(data)):\n        row = data.iloc[idx, :]\n        banks_review = row[banks]\n        unique_labels = set(banks_review)\n        unique_labels.remove('NULL')\n\n        # убираем все ненужные знаки\n        filtered_text = re.sub('http[A-z|:|.|/|0-9]*', '', row['text']).strip()\n        filtered_text = re.sub('@\\S*', '', filtered_text).strip()\n        filtered_text = re.sub('#', '', filtered_text).strip()\n        new_text = filtered_text\n\n        # сохраняем только уникальные токены (без придатка xml NULL)\n        unique_labels = list(unique_labels)\n        while len(unique_labels) < 2:\n            unique_labels.append(unique_labels[-1])\n        extracted_data['text'].append(new_text)\n        for idx, label in enumerate(unique_labels):\n            text_label = int(label) + 1\n            extracted_data[f'{idx}' + 'class'].append(text_label)\n\n    extracted_data = pd.DataFrame(extracted_data)\n    \n    # возвращаем dataframe\n    return extracted_data\n\nextracted_val = extract_text_features(data_test)\nextracted_train = extract_text_features(data_train)","metadata":{"_cell_guid":"e465b3aa-afb3-4491-ad48-3a8f07c88a7b","_uuid":"7c270cb9-6e6d-44e5-8aa9-5b9a81759385","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-10T00:04:20.534043Z","iopub.execute_input":"2023-12-10T00:04:20.534371Z","iopub.status.idle":"2023-12-10T00:04:28.202451Z","shell.execute_reply.started":"2023-12-10T00:04:20.534336Z","shell.execute_reply":"2023-12-10T00:04:28.201380Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"# пример твита из датасета\nextracted_val.iloc[3308].text","metadata":{"_cell_guid":"553036a6-e0cb-4859-9f43-fc8dd418894b","_uuid":"d874a823-0b6d-443d-b0cf-fee72b75b727","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-10T00:04:28.203638Z","iopub.execute_input":"2023-12-10T00:04:28.203934Z","iopub.status.idle":"2023-12-10T00:04:28.210344Z","shell.execute_reply.started":"2023-12-10T00:04:28.203909Z","shell.execute_reply":"2023-12-10T00:04:28.209381Z"},"trusted":true},"execution_count":113,"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"'Sberbank CIB: Цены на нефть по-прежнему остаются на очень низких уровнях РБК НПЗ стремятся отложить импортные…'"},"metadata":{}}]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# анализ распределения таргетов на твитах\nfig, axes = plt.subplots(1, 2, figsize=(8, 5))\nplt.subplots_adjust(hspace=0.3, wspace=0.5)\nfontsize=15\n\nsns.countplot(data=extracted_train, x='0class', ax=axes[0])\naxes[0].set_xlabel('class 0', fontsize=fontsize)\naxes[0].set_ylabel('count', fontsize=fontsize)\naxes[0].set_xticks([0, 1, 2], ['Neg', 'Neu', 'Pos'], fontsize=fontsize)\naxes[0].grid(True)\n\nsns.countplot(data=extracted_train, x='1class', ax=axes[1])\naxes[1].set_xlabel('class 1', fontsize=fontsize)\naxes[1].set_ylabel('count', fontsize=fontsize)\naxes[1].set_xticks([0, 1, 2], ['Neg', 'Neu', 'Pos'], fontsize=fontsize)\naxes[1].grid(True)\n\nfig.suptitle('target distribution', fontsize=fontsize)\n\nNone","metadata":{"_cell_guid":"d6af3578-6851-46ac-81ed-247202502f82","_uuid":"90899eeb-ca26-4010-9d08-888db203f310","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-10T00:04:28.212230Z","iopub.execute_input":"2023-12-10T00:04:28.212534Z","iopub.status.idle":"2023-12-10T00:04:28.622998Z","shell.execute_reply.started":"2023-12-10T00:04:28.212509Z","shell.execute_reply":"2023-12-10T00:04:28.622083Z"},"trusted":true},"execution_count":114,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x500 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"### Инициализируем модель (fine-tune) для решения нашей задачи классификации","metadata":{"_cell_guid":"84c3b206-9192-44d8-b0c3-99030962fbf1","_uuid":"27a39401-ac18-4df4-b723-57d39d511fb7","trusted":true}},{"cell_type":"code","source":"fn_model_name = \"DeepPavlov/distilrubert-base-cased-conversational\"\n\nclass BERTmy(torch.nn.Module):\n    def __init__(\n        self, model_name: str, n_classes: int, \n        use_tok_type_ids: bool, p: float=0.05\n    ) -> None:\n        super(BERTmy, self).__init__()\n        self.rubert = transformers.AutoModel.from_pretrained(\n            model_name\n        )\n        self.tokenizer = transformers.AutoTokenizer.from_pretrained(\n            model_name, \n            do_lower_case=True,\n            add_additional_tokens=True\n        )\n        self.use_tok_type_ids = use_tok_type_ids\n        \n        hidden_size_output = self.rubert.config.hidden_size\n        self.pre_classifier = torch.nn.Sequential(\n            torch.nn.Linear(hidden_size_output, hidden_size_output, bias=True),\n            torch.nn.Dropout(p),\n            torch.nn.ReLU()\n        )\n        self.classifier = torch.nn.Sequential(\n            torch.nn.Linear(hidden_size_output, hidden_size_output, bias=True),\n            torch.nn.Dropout(p),\n            torch.nn.ReLU(),\n            torch.nn.Linear(hidden_size_output, n_classes),\n        )\n\n    def forward(\n        self, input_ids: torch.Tensor, attention_mask: torch.Tensor, \n        token_type_ids: torch.Tensor=None, output_attentions: bool=False,\n        output_hidden_states: bool=False, return_dict: bool=True\n    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n        \n        input_dict = {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n            'return_dict': True,\n            'output_attentions': True,\n            'output_hidden_states': True\n        }\n        if self.use_tok_type_ids and not token_type_ids is None:\n            input_dict['token_type_ids'] = token_type_ids\n        \n        rubert_output = self.rubert(**input_dict)\n\n        pooled = rubert_output['last_hidden_state']\n        attentions = rubert_output['attentions']\n        hid_states = rubert_output['hidden_states']\n\n        output_pre_cls = self.pre_classifier(pooled[:, 0, :])\n        logits = self.classifier(output_pre_cls)\n\n        return {\n            'logits': logits,\n            'attentions': attentions,\n            'hidden_states': hid_states\n        }","metadata":{"execution":{"iopub.status.busy":"2023-12-10T00:04:28.624583Z","iopub.execute_input":"2023-12-10T00:04:28.624962Z","iopub.status.idle":"2023-12-10T00:04:28.638510Z","shell.execute_reply.started":"2023-12-10T00:04:28.624928Z","shell.execute_reply":"2023-12-10T00:04:28.637301Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"def load_model_hf(model_name: str, num_cls: int,  model_type: str, p: float=0.05) -> torch.nn.Module:\n\n    assert model_type in ['distilbert', 'bert']\n    \n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModel.from_pretrained(model_name)\n    model.config.update({\"seq_classif_dropout\":p})\n    model_cls = AutoModelForSequenceClassification.from_config(model.config)\n    \n    if model_type == 'distilbert':\n        model_cls.distilbert = model\n    elif model_type == 'bert':\n        model_cls.bert = model \n\n    hid_dim = model_cls.config.hidden_size\n    classifier = torch.nn.Sequential(\n        torch.nn.Linear(hid_dim, hid_dim, bias=True),\n        torch.nn.ReLU(),\n        torch.nn.Dropout(p),\n        torch.nn.Linear(hid_dim, num_cls, bias=True),\n    )\n    model_cls.classifier = classifier\n\n    del model\n\n    return model_cls, tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-12-10T00:04:28.639945Z","iopub.execute_input":"2023-12-10T00:04:28.640366Z","iopub.status.idle":"2023-12-10T00:04:28.654114Z","shell.execute_reply.started":"2023-12-10T00:04:28.640314Z","shell.execute_reply":"2023-12-10T00:04:28.652767Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"distilbert_name = \"DeepPavlov/distilrubert-base-cased-conversational\"\nbert_base_name = \"DeepPavlov/rubert-base-cased\"\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nnum_cls = len(pd.unique(extracted_train['0class']))\nload_tf = True\n\nif load_tf:\n    model_cls, tokenizer = load_model_hf(distilbert_name, num_cls, model_type='distilbert')\n    seq_max_len = model_cls.config.max_position_embeddings\nelse:\n    model_cls = BERTmy(model_name=distilbert_name, n_classes=num_cls, use_tok_type_ids=False)\n    tokenizer = model_cls.tokenizer\n    seq_max_len = model_cls.rubert.config.max_position_embeddings","metadata":{"execution":{"iopub.status.busy":"2023-12-10T00:05:45.127679Z","iopub.execute_input":"2023-12-10T00:05:45.128615Z","iopub.status.idle":"2023-12-10T00:05:49.707406Z","shell.execute_reply.started":"2023-12-10T00:05:45.128582Z","shell.execute_reply":"2023-12-10T00:05:49.706377Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at DeepPavlov/distilrubert-base-cased-conversational were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Инициализируем class для нашего датасета","metadata":{"_cell_guid":"a021a9f9-44ed-42a5-84c6-848e064b38a7","_uuid":"46a83749-640d-4bd6-9be0-7623bc16c690","trusted":true}},{"cell_type":"code","source":"train_batch_size = 16\nval_batch_size = 16\n\nclass SentimentDataTransformer(Dataset):\n    # инициализация датасета\n    def __init__(\n        self, texts: List[str], \n        labels: List[Tuple[int, ...]]\n    ) -> None:\n        \n        self.texts = texts\n        self.labels = labels\n\n    # для получения размера датасета\n    def __len__(self) -> int:\n        return len(self.texts)\n\n    # для получения элемента по индексу\n    def __getitem__(\n        self, index: int\n    ) -> Tuple[Union[str, int]]:\n        text = self.texts[index]\n        labels = self.labels[index]\n        \n        target1, target2 = labels\n\n        return text, target1, target2","metadata":{"_cell_guid":"4fe85b1d-d8b2-4be9-8b4e-dde97c2a4d42","_uuid":"9ba9fdee-22c8-4555-a26c-0bcec67ca8a9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-10T00:05:52.803022Z","iopub.execute_input":"2023-12-10T00:05:52.803386Z","iopub.status.idle":"2023-12-10T00:05:52.810642Z","shell.execute_reply.started":"2023-12-10T00:05:52.803360Z","shell.execute_reply":"2023-12-10T00:05:52.809546Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"class collate_fn_transformers():\n    \n    def __init__(\n        self, tokenizer: AutoTokenizer, \n        use_tok_type_ids: bool\n    ) -> None:\n        \n        self.tokenizer=tokenizer\n        self.use_tok_type_ids = use_tok_type_ids\n        \n    def __call__(self, batch):\n        \n        texts, target1, target2 = zip(*batch)\n        \n        input_ids = self.tokenizer(\n            texts, #truncation=True,\n            padding=True, add_special_tokens=True,\n            return_token_type_ids=self.use_tok_type_ids,\n            return_tensors='pt'\n        )\n        target1 = torch.tensor(target1)\n        target2 = torch.tensor(target2)\n        \n        return input_ids, target1, target2","metadata":{"execution":{"iopub.status.busy":"2023-12-10T00:05:53.052254Z","iopub.execute_input":"2023-12-10T00:05:53.052640Z","iopub.status.idle":"2023-12-10T00:05:53.059968Z","shell.execute_reply.started":"2023-12-10T00:05:53.052609Z","shell.execute_reply":"2023-12-10T00:05:53.058853Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"markdown","source":"### Инициализируем наши DataLoaders","metadata":{"_cell_guid":"ec214cce-6c71-4987-b673-f4f59b6e29f2","_uuid":"d72254d0-e70d-443a-9506-34554ec96efe","trusted":true}},{"cell_type":"code","source":"train = SentimentDataTransformer(\n    texts=extracted_train['text'].tolist(),\n    labels=list(zip(extracted_train['0class'], extracted_train['1class']))\n)\n\nval = SentimentDataTransformer(\n    texts=extracted_val['text'].tolist(),\n    labels=list(zip(extracted_val['0class'], extracted_val['1class']))\n)\n\ntrain_loader = DataLoader(\n    train, batch_size=train_batch_size, shuffle=True,\n    collate_fn=collate_fn_transformers(tokenizer=tokenizer, use_tok_type_ids=False)\n)\nval_loader = DataLoader(\n    val, batch_size=val_batch_size, shuffle=False,\n    collate_fn=collate_fn_transformers(tokenizer=tokenizer, use_tok_type_ids=False)\n)\nloaders = {\n    'train': train_loader,\n    'val': val_loader\n}","metadata":{"_cell_guid":"b5110fba-0208-4967-90fb-04bc71a68957","_uuid":"be40ab48-96e2-4c10-af39-36066c75dfc4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-10T00:05:53.637488Z","iopub.execute_input":"2023-12-10T00:05:53.638115Z","iopub.status.idle":"2023-12-10T00:05:53.650856Z","shell.execute_reply.started":"2023-12-10T00:05:53.638083Z","shell.execute_reply":"2023-12-10T00:05:53.649964Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"markdown","source":"### Дообучение модели","metadata":{"_cell_guid":"f4164662-55b5-43d0-ad49-7c57ea8eb62c","_uuid":"6c111c3b-95c7-4dc8-ba88-8f8bbce229dd","trusted":true}},{"cell_type":"code","source":"def train_model(\n    epochs: int, model: torch.nn.Module, loaders: Dict[str, DataLoader], \n    optimizer: torch.optim, scheduler: torch.optim.lr_scheduler, device: str='cpu'\n) -> None:\n    # cross entropy loss\n    model = model.to(device)\n    loss_function1 = torch.nn.CrossEntropyLoss(reduction='sum')\n    loss_function2 = torch.nn.CrossEntropyLoss(reduction='sum')\n    \n    # извлечение DataLoaders\n    if len(loaders) > 1:\n        train_loader = loaders['train']\n        val_loader = loaders['val']\n        steps_per_epoch = [('train', train_loader), ('val', val_loader)]\n    else:\n        train_loader = loaders['train']\n        steps_per_epoch = [('train', train_loader)]\n\n    # обучение по эпохам\n    for epoch in range(epochs):\n        for mode, loader in steps_per_epoch:\n            # сохранение статистик\n            train_loss = 0\n            n_correct = 0\n            processed_data = 0\n            \n            # train/val \n            if mode == 'train':\n                model.train()\n                requires_grad_mode = True\n            else:\n                model.eval()\n                requires_grad_mode = False\n            \n            # проход по батчам\n            for inputs, trg1, trg2 in tqdm(loader):\n                # обнуляем градиенты\n                optimizer.zero_grad()\n\n                # извлечение входных данных для модели\n                for key, value in inputs.items():\n                    inputs[key] = value.to(device)\n                trg1, trg2 = trg1.to(device), trg2.to(device)\n                inputs['return_dict'] = True\n                \n                # устанавливаем необходимость вычислять/не_вычислять градиенты\n                with torch.set_grad_enabled(requires_grad_mode):\n                    outputs = model(**inputs)\n                    preds = torch.argmax(outputs['logits'], dim=1)\n\n                    # настраиваем модели на конкретный target\n                    if all(trg1 == trg2):\n                        loss1 = loss_function1(outputs['logits'], trg1)\n                        train_loss += loss1.item()\n                        n_correct += torch.sum(preds == trg1).cpu().detach().numpy()\n                        if mode == 'train':\n                            # вычисляем градиенты и обновляем веса\n                            loss1.backward()\n                            optimizer.step()\n                    # если у твита более чем 1 метка, то настраиваем на обе\n                    else:\n                        loss1 = loss_function1(outputs['logits'], trg1) * 0.5\n                        loss2 = loss_function2(outputs['logits'], trg2) * 0.5\n                        loss_all = loss1 + loss2\n                        train_loss += loss_all.item()\n\n                        mask_singular = trg1 == trg2\n                        mask_multiple = trg1 != trg2\n                        singular = preds[mask_singular]\n                        n_correct += torch.sum(\n                            singular == trg1[mask_singular]\n                        ).cpu().detach().numpy()\n                        multiple = preds[mask_multiple]\n                        n_correct += torch.sum(\n                            (multiple == trg1[mask_multiple]) | (multiple == trg2[mask_multiple])\n                        ).cpu().detach().numpy()\n                        if mode == 'train':\n                            # вычисляем градиенты и обновляем веса\n                            loss_all.backward()\n                            optimizer.step()\n\n                    processed_data += len(preds)\n\n            # вычисляем ошибку и точность прогноза на эпохе\n            loader_loss = train_loss / processed_data\n            loader_acc = n_correct / processed_data\n            print(f'{epoch + 1} epoch with {mode} mode has: {loader_loss} loss, {loader_acc} acc')\n        \n        # делаем шаг для sheduler оптимайзера\n        scheduler.step()","metadata":{"_cell_guid":"8ab49c8f-c3fa-4786-a63b-fe6708927100","_uuid":"c349e8e4-a562-4927-aaa2-ac14f5dcf8df","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-10T00:05:54.208075Z","iopub.execute_input":"2023-12-10T00:05:54.208555Z","iopub.status.idle":"2023-12-10T00:05:54.226579Z","shell.execute_reply.started":"2023-12-10T00:05:54.208525Z","shell.execute_reply":"2023-12-10T00:05:54.225633Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"epochs = 3\noptimizer = torch.optim.Adam([\n    {'params': model_cls.pre_classifier.parameters(), 'lr': 8e-4},\n    {'params': model_cls.classifier.parameters(), 'lr': 8e-4}\n], lr=2e-6)\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\ntrain_model(epochs, model_cls, loaders, optimizer, scheduler, device)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T00:05:54.671818Z","iopub.execute_input":"2023-12-10T00:05:54.672186Z","iopub.status.idle":"2023-12-10T00:05:58.158580Z","shell.execute_reply.started":"2023-12-10T00:05:54.672157Z","shell.execute_reply":"2023-12-10T00:05:58.157368Z"},"trusted":true},"execution_count":130,"outputs":[{"name":"stderr","text":" 16%|█▌        | 95/587 [00:03<00:16, 30.65it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m7\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m\u001b[2m│   \u001b[0m{\u001b[33m'\u001b[0m\u001b[33mparams\u001b[0m\u001b[33m'\u001b[0m: model_cls.classifier.parameters(), \u001b[33m'\u001b[0m\u001b[33mlr\u001b[0m\u001b[33m'\u001b[0m: \u001b[94m8e-4\u001b[0m}                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m], lr=\u001b[94m2e-6\u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0mscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=\u001b[94m0.8\u001b[0m)                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m7 train_model(epochs, model_cls, loaders, optimizer, scheduler, device)                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m8 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mtrain_model\u001b[0m:\u001b[94m58\u001b[0m                                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m55 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mn_correct += torch.sum(preds == trg1).cpu().detach().numpy()        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m56 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m mode == \u001b[33m'\u001b[0m\u001b[33mtrain\u001b[0m\u001b[33m'\u001b[0m:                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m57 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[2m# вычисляем градиенты и обновляем веса\u001b[0m                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m58 \u001b[2m│   │   │   │   │   │   │   \u001b[0mloss1.backward()                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m59 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0moptimizer.step()                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m60 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# если у твита более чем 1 метка, то настраиваем на обе\u001b[0m                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m61 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m487\u001b[0m in \u001b[92mbackward\u001b[0m                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/autograd/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m200\u001b[0m in \u001b[92mbackward\u001b[0m               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m200 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run the bac\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine to ru\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mKeyboardInterrupt\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>{<span style=\"color: #808000; text-decoration-color: #808000\">'params'</span>: model_cls.classifier.parameters(), <span style=\"color: #808000; text-decoration-color: #808000\">'lr'</span>: <span style=\"color: #0000ff; text-decoration-color: #0000ff\">8e-4</span>}                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>], lr=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2e-6</span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span>scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.8</span>)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>7 train_model(epochs, model_cls, loaders, optimizer, scheduler, device)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_model</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">58</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>n_correct += torch.sum(preds == trg1).cpu().detach().numpy()        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">56 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> mode == <span style=\"color: #808000; text-decoration-color: #808000\">'train'</span>:                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">57 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># вычисляем градиенты и обновляем веса</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>58 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>loss1.backward()                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">59 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>optimizer.step()                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">60 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># если у твита более чем 1 метка, то настраиваем на обе</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">487</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 484 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>create_graph=create_graph,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 485 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 487 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 489 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># The reason we repeat same the comment below is that</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># some Python versions print out the first line of a multi-line function</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># calls in the traceback and some print out the last line</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the bac</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to ru</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"model_name = 'distilbert_cls.pth'\n\nmode_process = input('Load weights? (y/n)')\nif mode_process == 'n':\n    torch.save(model_cls.state_dict(), model_name)\nelif mode_process == 'y':\n    model_cls.load_state_dict(torch.load('/kaggle/input/distilbert-weights/distilbert_cls.pth'))\nelse:\n    assert mode_process in ['n', 'y']\nmodel_cls.eval()\nNone","metadata":{"_cell_guid":"2fa670b4-8330-4a79-ac62-d867928544f9","_uuid":"19503e86-4d81-4fd8-8a6e-f0f6f9891405","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T18:21:45.498326Z","iopub.execute_input":"2023-12-09T18:21:45.498680Z","iopub.status.idle":"2023-12-09T18:21:52.005632Z","shell.execute_reply.started":"2023-12-09T18:21:45.498639Z","shell.execute_reply":"2023-12-09T18:21:52.004696Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdin","text":"Load weights? (y/n) y\n"}]},{"cell_type":"markdown","source":"### Вычисление итоговых показателей","metadata":{"_cell_guid":"114d3f5e-6292-4964-8e88-7ed63b57100a","_uuid":"ed44b641-9164-4946-ac60-777b1b4afb6c","trusted":true}},{"cell_type":"code","source":"def calculate_accuracy(\n    model: torch.nn.Module, loader: DataLoader,\n    device: str='cpu'\n) -> float:\n    model.eval()\n    model = model.to(device)\n    n_correct = 0\n    processed_data = 0\n    \n    # проход по батчам\n    for inputs, trg1, trg2 in tqdm(loader):\n\n        # извлечение входных данных для модели\n        for key, value in inputs.items():\n            inputs[key] = value.to(device)\n        trg1, trg2 = trg1.to(device), trg2.to(device)\n        inputs['return_dict'] = True\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n            preds = torch.argmax(outputs['logits'], dim=1)\n            mask_singular = trg1 == trg2\n            mask_multiple = trg1 != trg2\n            singular = preds[mask_singular]\n            n_correct += torch.sum(\n                singular == trg1[mask_singular]\n            ).cpu().detach().numpy()\n            multiple = preds[mask_multiple]\n            if len(multiple) > 0:\n                n_correct += torch.sum(\n                    (multiple == trg1[mask_multiple]) | (multiple == trg2[mask_multiple])\n                ).cpu().detach().numpy()\n\n            processed_data += len(preds)\n        \n    loader_acc = n_correct / processed_data\n    \n    return loader_acc\n\ndef calculate_f1_class(\n    model: torch.nn.Module, loader: DataLoader,\n    class_num: int, device: str='cpu'\n) -> float:\n    model.eval()\n    model = model.to(device)\n    all_preds = list()\n    groud_truth = list()\n    \n    # проход по батчам\n    for inputs, trg1, trg2 in tqdm(loader):\n\n        # извлечение входных данных для модели\n        for key, value in inputs.items():\n            inputs[key] = value.to(device)\n        inputs['return_dict'] = True\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n            \n            preds = torch.argmax(\n                outputs['logits'], dim=1\n            ).cpu().numpy()\n            all_preds.append(preds)\n            groud_truth.append(trg1.cpu().detach().numpy())\n\n    all_preds = np.hstack(all_preds)\n    groud_truth = np.hstack(groud_truth)\n    mask = all_preds == class_num\n    all_preds[mask] = 1\n    all_preds[~mask] = 0\n    mask = groud_truth == class_num\n    groud_truth[mask] = 1\n    groud_truth[~mask] = 0\n    \n    return f1_score(groud_truth, all_preds)","metadata":{"_cell_guid":"26fee109-eaec-4b0f-a90d-a4d72ea6a9e1","_uuid":"ca969426-e888-4d62-ad59-39920e55edec","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T18:22:01.779961Z","iopub.execute_input":"2023-12-09T18:22:01.780888Z","iopub.status.idle":"2023-12-09T18:22:01.795449Z","shell.execute_reply.started":"2023-12-09T18:22:01.780851Z","shell.execute_reply":"2023-12-09T18:22:01.794168Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"test_acc = calculate_accuracy(model_cls, val_loader, device)\nclass_neg_f1 = calculate_f1_class(model_cls, val_loader, 0, device)\nclass_neu_f1 = calculate_f1_class(model_cls, val_loader, 1, device)\nclass_pos_f1 = calculate_f1_class(model_cls, val_loader, 2, device)","metadata":{"_cell_guid":"f327a64d-c8f8-4bab-b932-0a71697c3ef3","_uuid":"dcf7a5ab-948f-4a3f-a099-20d0781e3a0a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T17:54:55.245304Z","iopub.execute_input":"2023-12-09T17:54:55.246021Z","iopub.status.idle":"2023-12-09T17:56:27.319061Z","shell.execute_reply.started":"2023-12-09T17:54:55.245982Z","shell.execute_reply":"2023-12-09T17:56:27.318026Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"100%|██████████| 208/208 [00:30<00:00,  6.83it/s]\n100%|██████████| 208/208 [00:30<00:00,  6.76it/s]\n100%|██████████| 208/208 [00:30<00:00,  6.75it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# общая accuracy и f1 по классам\ntest_acc, class_neg_f1, class_neu_f1, class_pos_f1","metadata":{"_cell_guid":"82265fd8-c0bd-44d7-b9d8-aca69d404cb0","_uuid":"9b2b22cf-e842-40f4-b450-2dd7bf72d097","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T17:56:38.885950Z","iopub.execute_input":"2023-12-09T17:56:38.886322Z","iopub.status.idle":"2023-12-09T17:56:38.892233Z","shell.execute_reply.started":"2023-12-09T17:56:38.886291Z","shell.execute_reply":"2023-12-09T17:56:38.891290Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"(0.7642619981889526,\n 0.6403940886699507,\n 0.8417818740399385,\n 0.48148148148148145)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Backdoor attacks on neural network(adversial examples)","metadata":{"_cell_guid":"8882bdef-e71a-4445-8823-c6cd3ac91816","_uuid":"cac0e4f4-82dd-4140-9443-c4539d51a316","trusted":true}},{"cell_type":"markdown","source":"### USE metric for similarity between original sentence and spoiled sentence","metadata":{"_cell_guid":"c7a5f905-6e00-430b-a6b1-a9cb1ea55c89","_uuid":"2def7913-246a-4e98-8733-7579e3d96e4c","trusted":true}},{"cell_type":"code","source":"def use_score(original, adversial, use_bert_encoder=False, model=None):\n    from scipy.spatial.distance import cosine\n    # Load pre-trained universal sentence encoder model\n    if not use_bert_encoder:\n        # using DAN from tensorflow\n        use_encoder = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n\n        sentences_orig = list()\n        sentences_adv = list()\n        for pair in zip(original, adversial):\n            orig, adv = pair\n            sentences_orig.append(orig)\n            sentences_adv.append(adv)\n\n        # get embs of texts\n        sentences_orig_emb = use_encoder(sentences_orig)\n        sentences_adv_emb = use_encoder(sentences_adv)\n\n        # calculate use_score with DAN\n        use_scores = list()\n        for pair in zip(sentences_orig_emb, sentences_adv_emb):\n            orig_emb, adv_emb = pair[0], pair[1]\n            use_score_one = 1 - cosine(orig_emb, adv_emb)\n            use_scores.append(use_score_one)\n    else:\n        # using BERT itself\n        def get_inputs(text): # get inputs for model\n            inputs = model.tokenizer(\n                text, padding=True, \n                add_special_tokens=True, \n                return_tensors='pt'\n            )\n            ids = inputs['input_ids'].type(torch.long).to(device)\n            mask = inputs['attention_mask'].type(torch.long).to(device)\n            token_type_ids = inputs[\"token_type_ids\"].type(torch.long).to(device)\n            \n            return ids, mask, token_type_ids\n\n        # calculate use_score with BERT\n        use_scores = list()\n        for pair in zip(original, adversial):\n            orig, adv = pair[0], pair[1]\n            orig_inputs = get_inputs(orig)\n            adv_inputs = get_inputs(adv)\n            orig_outputs = model.rubert(*orig_inputs)\n            adv_outputs = model.rubert(*adv_inputs)\n            orig_pooled, adv_pooled = orig_outputs[1], adv_outputs[1]\n            orig_pooled = orig_pooled.cpu().detach().numpy()\n            adv_pooled = adv_pooled.cpu().detach().numpy()\n            use_score_one = 1 - cosine(orig_pooled, adv_pooled)\n            use_scores.append(use_score_one)\n    \n    return use_scores, np.mean(use_scores)","metadata":{"_cell_guid":"a2237584-a021-4633-a333-8413f2555a5f","_uuid":"e5c67eb2-846d-4e5e-aaf4-57493cfc825b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T18:22:05.080570Z","iopub.execute_input":"2023-12-09T18:22:05.081448Z","iopub.status.idle":"2023-12-09T18:22:05.093329Z","shell.execute_reply.started":"2023-12-09T18:22:05.081406Z","shell.execute_reply":"2023-12-09T18:22:05.092402Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Attention visualization","metadata":{"_cell_guid":"2fd87276-d681-4aa6-8cc4-d5824c8f3642","_uuid":"fdf759b2-374a-4203-892d-13259da64f14","trusted":true}},{"cell_type":"code","source":"def visualize_attention_one_head(tokens, attention_weights, num_layer, num_head):\n    # works only with batch_size=1\n    num_layer -= 1\n    num_head -= 1\n    assert num_head >= 0 and num_head < len(attention_weights[0][0])\n    assert num_layer < len(attention_weights) and num_layer >= 0\n    \n    attention_layer = attention_weights[num_layer][0].cpu().detach().numpy()\n    \n    fig, ax = plt.subplots(1, 1, figsize=(9, 6))\n\n    g = sns.heatmap(attention_layer[num_head], annot=True, linewidth=0.1, fmt='.1g')\n    # xlabel='weight_for_embed', ylabel='num_embed'\n    g.set(title=f'layer: {num_layer + 1}; head: {num_head + 1} attention map')\n    tickvalues = range(0,len(tokens) + 2)\n    tokens = ['CLS'] + tokens + ['SEP']\n    g.set_yticks(ticks=tickvalues ,labels=tokens, rotation='horizontal')\n    g.set_xticks(ticks=tickvalues ,labels=tokens, rotation='vertical')\n    ax = g\n    plt.show()","metadata":{"_cell_guid":"e3c4968e-a083-4284-a5c4-0b88a9592f00","_uuid":"733e2079-83b7-4298-9626-9e7575f915a9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T18:22:06.249530Z","iopub.execute_input":"2023-12-09T18:22:06.250607Z","iopub.status.idle":"2023-12-09T18:22:06.264738Z","shell.execute_reply.started":"2023-12-09T18:22:06.250549Z","shell.execute_reply":"2023-12-09T18:22:06.263481Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"adversial_examples_char = pd.read_csv('/kaggle/input/result-data/adversial_examples_char.csv')\ntext_example = extracted_val.iloc[10].text\ntext_example_ins = adversial_examples_char['1_ins_amount_1_SpoiledText'].iloc[10]\ntext_example_del = adversial_examples_char['1_del_amount_1_SpoiledText'].iloc[10]\ntext_example_sub = adversial_examples_char['1_sub_amount_1_SpoiledText'].iloc[10]","metadata":{"_cell_guid":"63054f35-5904-4e39-8871-37b2cfaf13ac","_uuid":"12f060c2-107c-4121-b231-a4079561b10c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T17:56:53.060843Z","iopub.execute_input":"2023-12-09T17:56:53.061203Z","iopub.status.idle":"2023-12-09T17:56:53.097232Z","shell.execute_reply.started":"2023-12-09T17:56:53.061177Z","shell.execute_reply":"2023-12-09T17:56:53.096417Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def visualize_attention_for_text(text, num_layer, num_head):\n    text_seq = bert.tokenizer(\n        text,\n        padding=True,\n        add_special_tokens=True,\n        return_tensors='pt'\n    ).to(device)\n    logits, attention = bert(**text_seq, output_attentions=True)\n    tokens = bert.tokenizer.tokenize(text)\n    visualize_attention_one_head(tokens, attention, num_layer, num_head)","metadata":{"_cell_guid":"ede9ac5a-c196-4cc1-b7c5-0ed241060268","_uuid":"52147ee1-2a73-4137-bd24-a043e4911b09","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T17:56:55.894597Z","iopub.execute_input":"2023-12-09T17:56:55.894998Z","iopub.status.idle":"2023-12-09T17:56:55.900762Z","shell.execute_reply.started":"2023-12-09T17:56:55.894967Z","shell.execute_reply":"2023-12-09T17:56:55.899813Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"visualize_attention_for_text(text_example_sub, 12, 1)","metadata":{"_cell_guid":"3c3b0df9-45ac-49e2-84d7-f4241dd80267","_uuid":"8c67df3a-86ce-4bf6-b915-49ec30ea8c11","collapsed":false,"execution":{"iopub.execute_input":"2023-12-04T23:18:15.793690Z","iopub.status.busy":"2023-12-04T23:18:15.793315Z","iopub.status.idle":"2023-12-04T23:18:16.475574Z","shell.execute_reply":"2023-12-04T23:18:16.474547Z","shell.execute_reply.started":"2023-12-04T23:18:15.793657Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### utils for generating adversarial text","metadata":{"_cell_guid":"c843d9f5-bff2-4a42-a9a0-6c0ee9d461c4","_uuid":"3f317f59-a082-4c84-a625-6a96ed49979c","trusted":true}},{"cell_type":"code","source":"key_errors = {\n    'й': ['ц', 'ы', 'ф'],\n    'ц': ['й', 'ы', 'у'],\n    'у': ['ц', 'в', 'к'],\n    'к': ['у', 'а', 'е'],\n    'е': ['к', 'п', 'н'],\n    'н': ['е', 'р', 'г'],\n    'г': ['н', 'о', 'ш'],\n    'ш': ['г', 'л', 'щ'],\n    'щ': ['ш', 'д', 'з'],\n    'з': ['щ', 'ж'],\n    'х': ['ъ', 'э', 'з'],\n    'ъ': ['э', 'х'],\n    'ф': ['й', 'ы', 'я'],\n    'ы': ['ц', 'в', 'ч', 'ф'],\n    'в': ['у', 'а', 'с', 'ы'],\n    'а': ['к', 'п', 'м', 'в'],\n    'п': ['е', 'р', 'и', 'а'],\n    'р': ['н', 'о', 'т', 'п'],\n    'о': ['г', 'л', 'ь', 'р'],\n    'л': ['ш', 'д', 'б', 'о'],\n    'д': ['щ', 'ж', 'ю', 'л', 'б'],\n    'ж': ['з', 'э', 'ю', 'д'],\n    'э': ['х', 'ъ', 'ж'],\n    'я': ['ф', 'ы', 'ч'],\n    'ч': ['ы', 'в', 'с', 'я'],\n    'с': ['в', 'а', 'м', 'ч'],\n    'м': ['а', 'п', 'и', 'с'],\n    'и': ['п', 'р', 'т', 'м'],\n    'т': ['р', 'о', 'ь', 'и'],\n    'ь': ['о', 'л', 'б', 'т'],\n    'б': ['ь', 'л', 'д', 'ю'],\n    'ю': ['д', 'ж', 'б'],\n    'r': ['t', 'f', 'e'],\n    't': ['y', 'f', 'e'],\n    '0': ['9', '-'],\n    '1': ['`', '2'],\n    '2': ['1', '3'],\n    '3': ['2', '4'],\n    '4': ['3', '5'],\n    '5': ['4', '6'],\n    '6': ['5', '7'],\n    '7': ['6', '8'],\n    '8': ['7', '9'],\n    '9': ['8', '0'],\n    '-': ['0', '+'],\n    'k': ['i', 'j', 'l', 'm'],\n    '.': [',', '/', 'l', ';']\n}\n# получаем словарь формата: буква -> ближайшие буквы на клавиатуре","metadata":{"_cell_guid":"273f1cd4-10e9-4c45-b3b7-e8da3516c7e5","_uuid":"8ea101b3-c750-46ed-8dfe-10aee7384980","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T18:22:09.556556Z","iopub.execute_input":"2023-12-09T18:22:09.556929Z","iopub.status.idle":"2023-12-09T18:22:09.569519Z","shell.execute_reply.started":"2023-12-09T18:22:09.556899Z","shell.execute_reply":"2023-12-09T18:22:09.568564Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Prepare data for adversarial generating","metadata":{}},{"cell_type":"code","source":"# выбираем текст для генерации состязательных примеров с сохранением исходной пропорции\nlimit_neu = 1300\nlimit_pos = 270\nlimit_neg = 550\nadversial_examples_pos = extracted_val[extracted_val['0class'] == 2]\nadversial_examples_neu = extracted_val[extracted_val['0class'] == 1]\nadversial_examples_neg = extracted_val[extracted_val['0class'] == 0]\n\nadversial_examples_pos = adversial_examples_pos.head(limit_pos)\nadversial_examples_neu = adversial_examples_neu.head(limit_neu)\nadversial_examples_neg = adversial_examples_neg.head(limit_neg)\n\nadversial_examples = pd.concat([adversial_examples_pos, adversial_examples_neu, adversial_examples_neg])\nadversial_examples_char = adversial_examples.sample(frac=1)\n\nprint('Размер текста для генерации: ', len(adversial_examples_char))\nprint('Баланс классов: ')\nprint(np.unique(adversial_examples_char['0class'], return_counts=True))","metadata":{"_cell_guid":"0dd827a1-3317-4285-9dab-79b4e96d78c8","_uuid":"da7eac17-3985-45b6-b1c5-8c0ff4a8950c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T18:22:10.472002Z","iopub.execute_input":"2023-12-09T18:22:10.472362Z","iopub.status.idle":"2023-12-09T18:22:10.484880Z","shell.execute_reply.started":"2023-12-09T18:22:10.472333Z","shell.execute_reply":"2023-12-09T18:22:10.483956Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Размер текста для генерации:  2120\nБаланс классов: \n(array([0, 1, 2]), array([ 550, 1300,  270]))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Work with word importance","metadata":{}},{"cell_type":"code","source":"use_alti=True\n\nif use_alti:\n    model_cls_wrapped = ModelWrapper(model_cls)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:15:25.342747Z","iopub.execute_input":"2023-12-09T19:15:25.343175Z","iopub.status.idle":"2023-12-09T19:15:25.348523Z","shell.execute_reply.started":"2023-12-09T19:15:25.343142Z","shell.execute_reply":"2023-12-09T19:15:25.347430Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"def gather_back_tokens(tokens: List[str], tokens_type: str) -> str:\n    \"\"\"\n    для превращения токенов в предложение\n    tokens: список токенов\n    tokens_type: natasha или razdel\n    \"\"\"\n    assert tokens_type in ['razdel', 'natasha']\n\n    sent = ''\n    prev_end = None\n    for token in tokens:\n\n        if tokens_type == 'natasha':\n            token_text = token['text']\n            token_start, token_stop = token['start'], token['stop']\n        else:\n            token_text = token.text\n            token_start, token_stop = token.start, token.stop\n        \n        if not prev_end is None:\n            sent += (token_start - prev_end) * ' '\n\n        sent += token_text\n        prev_end = token_stop\n \n    return sent\n\n\ndef predict_texts(texts: List[str]):\n    \"\"\"\n    for Lime: return probability distribution of text\n    \"\"\"\n    # get model outputs\n    all_probs = list()\n    for text in texts:\n        inputs = tokenizer(\n            text, truncation=True, padding='max_length', max_length=seq_max_len, \n            add_special_tokens=True, return_token_type_ids=False, return_tensors='pt'\n        )\n        for key, value in inputs.items():\n            inputs[key] = value.to(device)\n        inputs['return_dict'] = True\n\n        with torch.no_grad():\n            logits = model_cls(**inputs)['logits']\n\n        # get probs\n        probs = torch.nn.functional.softmax(\n            logits, dim=1\n        ).cpu().detach().numpy()\n        all_probs.append(probs)\n\n    return np.vstack(all_probs)\n\n\ndef RazdelSplit(text):\n        \n    return [raz_tok.text for raz_tok in list(tokenize(text))]\n\ndef NatashaSplit(text):\n    \n    segmenter = Segmenter()\n    text_doc = Doc(text.lower())\n    text_doc.segment(segmenter)\n    \n    return [nat_tok['text'] for nat_tok in text_doc]\n\n\n# get words score to final output\ndef extract_essential_words(\n    tokens: List[str], target: int, imoprtance: str, \n    tokens_type: str, num_samples: int=300, num_features: int=150\n) -> List[Tuple[str, int]]:\n    \"\"\"\n    возвращает список слов по убыванию важности\n    причем если на вход поданы токены natasha\n    то вернет токены natasha\n    а если на вход - токены razdel\n    то вернет токены razdel\n    \"\"\"\n\n    assert imoprtance in ['loss', 'lime', 'shap', 'alti']\n    assert tokens_type in ['razdel', 'natasha']\n\n    # список для наиболее важных слов\n    essential_words = list()\n    \n    # восстанавливаем текст из слов\n    text_to_explain = gather_back_tokens(tokens,tokens_type)\n\n    if imoprtance == 'lime':\n        \n        if tokens_type == 'razdel':\n            Spliter = RazdelSplit\n        elif token_type == 'natasha':\n            Spliter = NatashaSplit\n        # создаем Explainer\n        explainer = LimeTextExplainer(\n            class_names=['Neg', 'Neu', 'Pos'],\n            split_expression=Spliter\n        )\n\n        # \"объясняем\" текст\n        explanation = explainer.explain_instance(\n            text_to_explain, predict_texts, \n            num_features=num_features, num_samples=num_samples\n        )\n\n        # создаем mapping из токена в его вес LogReg\n        explanation_list = explanation.as_list()\n        tok2weight = {token:weight for token, weight in explanation_list}\n\n        # создаем список из токенов, их важности и позиции в тексте\n        for token in tokens:\n            if tokens_type == 'razdel':\n                token_text = token.text.lower()\n            else:\n                token_text = token['text'].lower()\n            \n            essential_words.append((\n                token, tok2weight[token_text]\n            ))\n        \n        # создаем функцию сравнения важности\n        sort_func = lambda x: np.abs(x[1])\n    \n    elif imoprtance == 'shap':\n\n        def f(x):\n            print(x)\n            import time\n            time.sleep(1)\n            tv = torch.tensor(\n                [\n                    tokenizer.encode(v, padding=\"max_length\", max_length=128, truncation=True)\n                    for v in x\n                ]\n            ).cuda()\n            attention_mask = (tv != 0).type(torch.int64).cuda()\n            outputs = model(tv, attention_mask=attention_mask)[0].detach().cpu().numpy()\n            scores = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n            val = sp.special.logit(scores)\n            return val\n\n        def custom_tokenizer(s, return_offsets_mapping=True):\n            \"\"\"Custom tokenizers conform to a subset of the transformers API.\"\"\"\n            pos = 0\n            offset_ranges = []\n            input_ids = []\n            for m in re.finditer(r\"\\W\", s):\n                start, end = m.span(0)\n                offset_ranges.append((pos, start))\n                input_ids.append(s[pos:start])\n                pos = end\n            if pos != len(s):\n                offset_ranges.append((pos, len(s)))\n                input_ids.append(s[pos:])\n            out = {}\n            out[\"input_ids\"] = input_ids\n            if return_offsets_mapping:\n                out[\"offset_mapping\"] = offset_ranges\n            return out\n\n        masker = shap.maskers.Text(custom_tokenizer)\n        explainer = shap.Explainer(f, masker, output_names=labels)\n\n    elif imoprtance == 'alti':\n\n        inputs = tokenizer(\n            text_to_explain, truncation=True, padding=True, return_token_type_ids=False, \n            return_tensors='pt', return_offsets_mapping=True\n        )\n        offsets_mapping = inputs['offset_mapping']\n        del inputs['offset_mapping']\n\n        _, _, _, contributions_data = model_cls_wrapped(inputs.to(device))\n\n        resultant_norm = resultants_norm = torch.norm(torch.squeeze(\n            contributions_data['resultants']\n        ),p=1,dim=-1)\n        normalized_contributions = normalize_contributions(\n            contributions_data['contributions'], scaling='min_sum',\n            resultant_norm=resultant_norm\n        )\n        \n        # alti\n        ### get rollout composition\n        contributions_mix = compute_joint_attention(normalized_contributions)\n        ### get last Ci matrix\n        joint_attention_layer = -1\n        Clast = contributions_mix[joint_attention_layer]\n        ### get contribution to cls token\n        cls_pos_contribution = 0\n        contributions_mix_cls = Clast[cls_pos_contribution]\n        tokens_contributions = contributions_mix_cls[1:-1].c\n        \n    elif imoprtance == 'loss':\n        \n        loss = torch.nn.CrossEntropyLoss()\n        \n        # get inputs and outputs from model\n        ids, mask, token_type_ids = get_inputs(text_to_explain)\n        outputs = bert(ids, mask, token_type_ids)\n\n        # calculate loss for original text\n        loss_score_integral = loss(outputs.cpu(), torch.tensor([target], dtype=torch.long))\n\n        for idx, token in enumerate(tokens):\n            # get text without one token\n            tokens_copy = tokens.copy()\n            tokens_copy.pop(idx)\n            text_to_explain = gather_back_tokens(tokens_copy, tokens_type=tokens_type)\n\n            # calculate loss without current word\n            ids, mask, token_type_ids = get_inputs(text_to_explain)\n            with torch.no_grad():\n                outputs = bert(ids, mask, token_type_ids)\n            loss_score_part = loss(outputs.cpu(), torch.tensor([target], dtype=torch.long))\n            # add our score of change\n            essential_words.append((\n                token, (loss_score_part - loss_score_integral).cpu().detach().numpy()\n            ))\n            # создаем функцию сравнения важности\n            sort_func = lambda x: x[1]\n    \n    # сортируем токены по важности\n    essential_words = sorted(essential_words, key=sort_func, reverse=True)\n\n    # возвращаем только слова и их позиции в тексте\n    essential_words = [word for word, _ in essential_words]\n\n    return essential_words\n\n\ndef extract_random_words(\n    tokens: List[str]\n) -> List[Tuple[str, int]]:\n    \"\"\"\n    возвращает список слов в случайном порядке\n    \"\"\"\n    permutation = np.random.permutation(len(tokens))\n\n    return [tokens[idx] for idx in permutation]","metadata":{"_cell_guid":"ff82fe94-6beb-4d7b-af9c-702319834adc","_uuid":"be5751b8-0b73-423e-9ae0-4a90461d1648","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T19:31:26.980144Z","iopub.execute_input":"2023-12-09T19:31:26.980524Z","iopub.status.idle":"2023-12-09T19:31:27.014452Z","shell.execute_reply.started":"2023-12-09T19:31:26.980490Z","shell.execute_reply":"2023-12-09T19:31:27.013460Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"markdown","source":"## char-level attacks","metadata":{"_cell_guid":"32811848-cf03-4d3e-a485-607a1e879aa1","_uuid":"ae956c6a-8df7-420b-8a63-ccaef04b1ac6","trusted":true}},{"cell_type":"code","source":"# функция для генерации состязательных примеров на уровне символов\ndef extract_spoiled_text_char_level(\n        dataframe, words2spoil=2, \n        sub_percent=0.15, sub_amount=1,\n        mode2spoil='mixed', mode2amount='percent',\n        importance='loss'\n    ):\n\n\n    def get_indexes2change(\n        sub_letter: int, token_len: int\n    ) -> List[int]:\n        \"\"\"\n        функция для получения индексов букв на замену (кроме 0)\n        \"\"\"\n        lst_to_random = list(range(1, token_len))\n        np_ids = np.random.choice(lst_to_random, size=sub_letter, replace=False)\n\n        return np_ids.tolist()\n    \n    def make_token_change(\n        indexes: List[int], token: str, mode='mixed'\n    ):\n        \"\"\"\n        фукнция для замены букв по индексам с использованием 4 типов замены:\n        del: только удаление\n        ins: только вставка\n        sub: только замена\n        mixed: все вместе сразу\n        \"\"\"\n        if mode == 'sub':\n            # заменяем букву на позиции\n            word = list(token.text)\n            for idx in indexes:\n                symbol = word[idx]\n                try:\n                    word[idx] = key_errors[symbol][random.randint(0, len(key_errors[symbol])-1)]\n                except:\n                    pass\n            return (token.start, token.stop, ''.join(word), 0)\n        elif mode == 'ins':\n            # вставляем букву на позиция и увеличиваем длину токена на 1\n            ins_count = 0\n            word = list(token.text)\n            indexes = sorted(indexes)\n            for idx in indexes:\n                symbol = word[idx+ins_count]\n                try:\n                    word.insert(idx+ins_count, key_errors[symbol][random.randint(0, len(key_errors[symbol]) - 1)])\n                    ins_count += 1\n                except:\n                    pass\n            return (token.start, token.stop, ''.join(word), ins_count)\n        elif mode == 'del':\n            # удаляем букву на позиция и уменьшаем длину токена на 1\n            del_count = 0\n            word = list(token.text)\n            indexes = sorted(indexes)\n            for idx in indexes:\n                if len(word) == 1:\n                    break\n                try:\n                    word.pop(idx-del_count)\n                    del_count += 1\n                except:\n                    pass\n            return (token.start, token.stop, ''.join(word), -del_count)\n        elif mode == 'mixed':\n            ins_count = 0\n            del_count = 0\n            word = list(token.text)\n            # генерируем самое первое действие в слове\n            idx2action = random.randint(0, 2)\n            indexes = sorted(indexes)\n            for idx in indexes:\n                # вставляем букву на позиция и увеличиваем длину токена на 1, если ins\n                # удаляем букву на позиция и уменьшаем длину токена на 1, если del\n                # заменяем букву на позиции, если sub\n                new_idx = idx+ins_count-del_count\n                try:\n                    if idx2action == 0:\n                        symbol = word[new_idx]\n                        word[new_idx] = key_errors[symbol][random.randint(0, len(key_errors[symbol]) - 1)]\n                        idx2action += 1\n                    elif idx2action == 1:\n                        word.insert(new_idx, key_errors[symbol][random.randint(0, len(key_errors[symbol]) - 1)])\n                        ins_count += 1\n                        idx2action += 1\n                    elif idx2action == 2:\n                        word.pop(new_idx)\n                        del_count += 1\n                        idx2action = 0 \n                except:\n                    pass\n            return (token.start, token.stop, ''.join(word), ins_count-del_count)\n\n    # spoiled texts\n    spoiled_text = list()\n    pbar = tqdm(dataframe['text'], leave=True, position=0)\n    for idx, sent, target1 in zip(\n        range(len(dataframe['text'])), \n        dataframe['text'], \n        dataframe['0class']\n    ):\n        # get tokens of our text\n        tokens = [data for data in list(tokenize(sent.lower()))]\n        # just one word\n        if len(tokens) == 1:\n            spoiled_text.append(sent)\n            continue\n\n        # выбираем определенным методом наиболее важные слова\n        if importance in ['loss', 'lime', 'shap', 'alti']:\n            word2spoil_order = extract_essential_words(\n                tokens, target1, importance, tokens_type='razdel'\n            )\n        # выбираем случайным образом наиболее важные слова\n        elif importance == 'random':\n            word2spoil_order = extract_random_words(tokens)\n\n        sub_count = 0\n        spoiled_tokens = list()\n        for token in word2spoil_order:\n            # get token and token's position\n            token_len = token.stop - token.start\n            # no way to change\n            if token_len != 1 and sub_count < words2spoil: \n                # count our changes\n                if mode2amount == 'percent':\n                    sub_letter = max(1, int(token_len * sub_percent))\n                elif mode2amount == 'amount':\n                    sub_letter = max(1, sub_amount)\n                # get indexes to change\n                indexes = get_indexes2change(sub_letter, token_len)\n                # go through indexes\n                spoiled_word = make_token_change(indexes, token, mode2spoil)\n                # increase our subs\n                sub_count += 1\n                spoiled_tokens.append(spoiled_word)\n            # сделали нужное количество порч\n            if sub_count >= words2spoil:\n                break\n        \n        # заменяем исходные слов в тексте испорченными\n        shift_in_sent = 0\n        spoiled_sent = list(sent.lower())\n        spoiled_tokens = sorted(spoiled_tokens, key=lambda x:x[0])\n        for spoiled in spoiled_tokens:\n            spoiled_start, spoiled_stop, spoiled_word, word_shift = spoiled\n            spoiled_sent[spoiled_start + shift_in_sent:spoiled_stop + shift_in_sent] = spoiled_word\n            shift_in_sent += word_shift\n        spoiled_sent = ''.join(spoiled_sent)\n        spoiled_text.append(spoiled_sent)\n        \n        pbar.update(1)\n        pbar.set_description(f'Total processed: {idx + 1}')\n        \n    return spoiled_text","metadata":{"_cell_guid":"e083c436-9f81-4544-9205-387e75d2a8b1","_uuid":"d71ca614-f090-4867-9dd3-9a831b34223c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T19:31:27.367875Z","iopub.execute_input":"2023-12-09T19:31:27.368205Z","iopub.status.idle":"2023-12-09T19:31:27.393411Z","shell.execute_reply.started":"2023-12-09T19:31:27.368178Z","shell.execute_reply":"2023-12-09T19:31:27.392501Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":"### Портим текст, вычисляем показатель use_score и accuracy","metadata":{"_cell_guid":"8d5f880d-9df6-4595-96c2-5e31988b8d76","_uuid":"6ea8af42-a20a-45aa-8c3e-f7f9f58d8804","trusted":true}},{"cell_type":"code","source":"def get_scores_char_spoiled_text(\n        model: torch.nn.Module, dataframe: pd.DataFrame, \n        words2spoil: List[int], mode2amount: str,\n        sub_amount: List[int], sub_percent: List[float],\n        spoil_modes: List[str], importances: List[str]\n    ) -> Tuple[Dict[str, float], Dict[str, float], Dict[str, float], pd.DataFrame]:\n    \"\"\"\n    dataframe: (pandas данные с текстом и метками)\n    mode2amount: 'percent', 'amount' (по процентам или по количеству букв)\n    words2spoil_amount: (количество слов для порчи)\n    subs: (сколько букв испортить)\n    subs_percent: (сколько букв в процентах от слова испортить)\n    spoil_modes: 'mixed', 'ins', 'del', 'sub' (способы порчи текста)\n    spoil_init: 'random', 'loss', 'lime' (тип выбора слов для порчи)\n    \"\"\"\n    \n    assert mode2amount in ['percent', 'amount']\n    assert set(importances) <= {'loss', 'shap', 'lime', 'random', 'alti'}\n    assert set(spoil_modes) <= {'mixed', 'ins', 'del', 'sub'}\n    assert all(amount > 0 for amount in words2spoil)\n    assert all(sub >= 1 for sub in sub_amount)\n    assert all(sub >= 0.05 for sub in sub_percent)\n    \n    dan_scores = dict()\n    bert_scores = dict()\n    acc_scores = dict()\n    \n    subs = sub_percent if mode2amount == 'percent' else sub_amount\n\n    for importance in importances:\n        for sub in subs:\n            for mode2spoil in spoil_modes:\n                for words_amount in words2spoil:\n\n                    col_name = f'{importance}_{words_amount}_{mode2spoil}_{mode2amount}_{sub}_CharSpoiledText'\n                    # генерируем состязательные примеры\n                    spoiled_text = extract_spoiled_text_char_level(\n                        dataframe, words2spoil=words_amount,\n                        sub_amount=sub, sub_percent=sub, mode2amount=mode2amount, \n                        mode2spoil=mode2spoil, importance=importance\n                    )\n                    \n                    # сохраняем колонку со состязательными примерами\n                    dataframe[col_name] = spoiled_text\n                    \n                    # считаем use score на основе представлений bert\n                    _, use_result_char_bert = use_score(\n                        dataframe['text'],\n                        dataframe[col_name],\n                        use_bert_encoder=True,\n                        model=model\n                    )\n                    # считаем use score на основе dan кодировщика\n                    _, use_result_char = use_score(\n                        dataframe['text'],\n                        dataframe[col_name]\n                    )\n\n                    sentidata = SentimentDataTransformer(\n                        texts=..., labels=...\n                    )\n                    \n                    loader_sentidata = DataLoader(\n                        sentidata, batch_size=16, shuffle=False,\n                        collate_fn=collate_fn_transformers(\n                            tokenizer=tokenizer, use_tok_type_ids=False, max_len=seq_mas_len\n                        )\n                    )\n\n                    # замеряем качество состязательных примеров\n                    spoiled_accuracy_char = calculate_accuracy(model, loader_sentidata, device)\n                    \n                    # сохраняем результаты\n                    dan_scores[col_name] = use_result_char\n                    bert_scores[col_name] = use_result_char_bert\n                    acc_scores[col_name] = spoiled_accuracy_char\n                \n    return dan_scores, bert_scores, acc_scores, dataframe","metadata":{"_cell_guid":"efa44e96-a095-433f-91c6-fe487359e517","_uuid":"1d64853f-94d1-4a6c-ac78-9bde88701737","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T19:31:27.680606Z","iopub.execute_input":"2023-12-09T19:31:27.681514Z","iopub.status.idle":"2023-12-09T19:31:27.696068Z","shell.execute_reply.started":"2023-12-09T19:31:27.681476Z","shell.execute_reply":"2023-12-09T19:31:27.695197Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"mode2amount = 'amount'\nsub_amount, sub_percent = [1], [0.05]\nspoil_modes = ['ins', 'del', 'sub']\nimportances = ['alti']\nwords2spoil_amount = [1, 2]\n\ndan_scores_char, bert_scores_char, acc_scores_char, adversial_examples_char = get_scores_char_spoiled_text(\n    model_cls, adversial_examples_char,\n    words2spoil=words2spoil_amount,\n    mode2amount=mode2amount,\n    sub_amount=sub_amount, sub_percent=sub_percent,\n    spoil_modes=spoil_modes, importances=importances\n)","metadata":{"_cell_guid":"99b6d519-3d2f-4d94-919a-15807f99a32d","_uuid":"ad6d6ffe-47cf-46ae-958d-effdfa8438ee","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-09T19:31:28.281570Z","iopub.execute_input":"2023-12-09T19:31:28.281926Z","iopub.status.idle":"2023-12-09T19:31:31.665654Z","shell.execute_reply.started":"2023-12-09T19:31:28.281891Z","shell.execute_reply":"2023-12-09T19:31:31.664432Z"},"trusted":true},"execution_count":116,"outputs":[{"name":"stderr","text":"  0%|          | 0/2120 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"tensor([0.0135, 0.0242, 0.0348, 0.0460, 0.0199, 0.0563, 0.0237, 0.0744, 0.0480,\n        0.0426, 0.0484, 0.0566, 0.0419, 0.0342, 0.1074, 0.1634, 0.1057, 0.0591])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m7\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0mimportances = [\u001b[33m'\u001b[0m\u001b[33malti\u001b[0m\u001b[33m'\u001b[0m]                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0mwords2spoil_amount = [\u001b[94m1\u001b[0m, \u001b[94m2\u001b[0m]                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 7 dan_scores_char, bert_scores_char, acc_scores_char, adversial_examples_char = get_scores    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   \u001b[0mmodel_cls, adversial_examples_char,                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   \u001b[0mwords2spoil=words2spoil_amount,                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   \u001b[0mmode2amount=mode2amount,                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mget_scores_char_spoiled_text\u001b[0m:\u001b[94m37\u001b[0m                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m34 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcol_name = \u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mimportance\u001b[33m}\u001b[0m\u001b[33m_\u001b[0m\u001b[33m{\u001b[0mwords_amount\u001b[33m}\u001b[0m\u001b[33m_\u001b[0m\u001b[33m{\u001b[0mmode2spoil\u001b[33m}\u001b[0m\u001b[33m_\u001b[0m\u001b[33m{\u001b[0mmode2amount\u001b[33m}\u001b[0m\u001b[33m_\u001b[0m    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# генерируем состязательные примеры\u001b[0m                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m37 \u001b[2m│   │   │   │   │   \u001b[0mspoiled_text = extract_spoiled_text_char_level(                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m38 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mdataframe, words2spoil=words_amount,                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m39 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0msub_amount=sub, sub_percent=sub, mode2amount=mode2amount,           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m40 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mmode2spoil=mode2spoil, importance=importance                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mextract_spoiled_text_char_level\u001b[0m:\u001b[94m114\u001b[0m                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# выбираем определенным методом наиболее важные слова\u001b[0m                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m importance \u001b[95min\u001b[0m [\u001b[33m'\u001b[0m\u001b[33mloss\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33mlime\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33mshap\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33malti\u001b[0m\u001b[33m'\u001b[0m]:                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   │   \u001b[0mword2spoil_order = extract_essential_words(                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtokens, target1, importance, tokens_type=\u001b[33m'\u001b[0m\u001b[33mrazdel\u001b[0m\u001b[33m'\u001b[0m                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# выбираем случайным образом наиболее важные слова\u001b[0m                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mextract_essential_words\u001b[0m:\u001b[94m197\u001b[0m                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m194 \u001b[0m\u001b[2m│   │   \u001b[0mcontributions_mix_cls = Clast[cls_pos_contribution]                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(contributions_mix_cls)                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m196 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mtime\u001b[0m                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m197 \u001b[2m│   │   \u001b[0mtime.sleep(\u001b[94m100\u001b[0m)                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m imoprtance == \u001b[33m'\u001b[0m\u001b[33mloss\u001b[0m\u001b[33m'\u001b[0m:                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mKeyboardInterrupt\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>importances = [<span style=\"color: #808000; text-decoration-color: #808000\">'alti'</span>]                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>words2spoil_amount = [<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>]                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 7 dan_scores_char, bert_scores_char, acc_scores_char, adversial_examples_char = get_scores    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>model_cls, adversial_examples_char,                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>words2spoil=words2spoil_amount,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>mode2amount=mode2amount,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_scores_char_spoiled_text</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">37</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>col_name = <span style=\"color: #808000; text-decoration-color: #808000\">f'{</span>importance<span style=\"color: #808000; text-decoration-color: #808000\">}_{</span>words_amount<span style=\"color: #808000; text-decoration-color: #808000\">}_{</span>mode2spoil<span style=\"color: #808000; text-decoration-color: #808000\">}_{</span>mode2amount<span style=\"color: #808000; text-decoration-color: #808000\">}_</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># генерируем состязательные примеры</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>37 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>spoiled_text = extract_spoiled_text_char_level(                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>dataframe, words2spoil=words_amount,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">39 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>sub_amount=sub, sub_percent=sub, mode2amount=mode2amount,           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">40 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>mode2spoil=mode2spoil, importance=importance                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">extract_spoiled_text_char_level</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">114</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># выбираем определенным методом наиболее важные слова</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> importance <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> [<span style=\"color: #808000; text-decoration-color: #808000\">'loss'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'lime'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'shap'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'alti'</span>]:                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>114 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>word2spoil_order = extract_essential_words(                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>tokens, target1, importance, tokens_type=<span style=\"color: #808000; text-decoration-color: #808000\">'razdel'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># выбираем случайным образом наиболее важные слова</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">extract_essential_words</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">197</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">194 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>contributions_mix_cls = Clast[cls_pos_contribution]                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(contributions_mix_cls)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">time</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>197 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>time.sleep(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">100</span>)                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> imoprtance == <span style=\"color: #808000; text-decoration-color: #808000\">'loss'</span>:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">200 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"### Сохраняем все результаты","metadata":{"_cell_guid":"c6b59874-65d5-467a-af95-3163f18e52c9","_uuid":"416b233b-03d4-482f-999b-0f486ac4df96","trusted":true}},{"cell_type":"code","source":"# сохраняем состязательные примеры\nadversial_examples_char.to_csv('adversial_examples_char.csv')\n\n# создание pd.DataFrame с бъединенными данными\nscores = [dan_scores_char, bert_scores_char, acc_scores_char]\nnames = ['dan_score', 'bert_score', 'acc_score']\ndataframes = list()\n\n# создаем список отдельных dataframe\nfor name, score in zip(names, scores):\n    score_dct = {\n        'modification': list(),\n        name: list()\n    }\n    for key, val in score.items():\n        score_dct['modification'].append(key)\n        score_dct[name].append(val)\n    dataframes.append(pd.DataFrame(score_dct))\n\n# merge всех dataframe\ninit_dataframe = dataframes[0]\nfor i in range(1, len(dataframes)):\n    init_dataframe = init_dataframe.merge(dataframes[i], how='left', on='modification')\n\ninit_dataframe['importance'] = init_dataframe['modification'].apply(lambda x: x.split('_')[0])\ninit_dataframe['modification'] = init_dataframe['modification'].apply(lambda x: '_'.join(x.split('_')[1:]))\n\n# init_dataframe = init_dataframe.set_index('modification')","metadata":{"_cell_guid":"5e6d79b8-7e9f-4ac7-95c4-23939007d726","_uuid":"329e80fe-92d5-44ba-8ede-646087b2dbe5","collapsed":false,"execution":{"iopub.execute_input":"2023-12-05T00:03:25.641255Z","iopub.status.busy":"2023-12-05T00:03:25.640654Z","iopub.status.idle":"2023-12-05T00:03:25.670652Z","shell.execute_reply":"2023-12-05T00:03:25.669927Z","shell.execute_reply.started":"2023-12-05T00:03:25.641220Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Графики зависимостей символов","metadata":{"_cell_guid":"17e1e040-5c3a-4c1b-ab06-d5c0de7dd007","_uuid":"005cac6e-0f3b-4114-9b53-9648f2328ab3","trusted":true}},{"cell_type":"code","source":"orig_acc = 0.762\norig_dan = 1\norig_use = 1\n\ndef plot_char_results(method: str, modification2value: Dict[str, float]) -> None:\n    \n    # сохраняем mappings от (способ порчи, кол-во испорченных слов)\n    # к полученному результату\n    bert_method_to_res = dict()\n    acc_method_to_res = dict()\n    dan_method_to_res = dict()\n    # есть ли в результатах данный метод оценки важности слова\n    used_method = False\n    # получаем имена всех модификаций\n    modifications = modification2value.keys()\n    for modification in modifications:\n        modification_parts = modification.split('_')\n        # получаем характеристики модификации\n        importance = modification_parts[0]\n        spoil_method = modification_parts[2]\n        words_amount = modification_parts[1]\n        sub = modification_parts[4]\n        # если хотим визуализировать другой метод\n        if importance != method:\n            continue\n        used_method = True\n        # получаем и сохраняем результаты\n        bert_score = bert_scores_char[modification]\n        dan_score = dan_scores_char[modification]\n        acc_score = acc_scores_char[modification]\n        \n        if bert_method_to_res.get((spoil_method, words_amount), None) is None:\n            bert_method_to_res[(spoil_method, words_amount)] = [(orig_acc, 0)]\n        if dan_method_to_res.get((spoil_method, words_amount), None) is None:\n            dan_method_to_res[(spoil_method, words_amount)] = [(orig_dan, 0)]\n        if acc_method_to_res.get((spoil_method, words_amount), None) is None:\n            acc_method_to_res[(spoil_method, words_amount)] = [(orig_use, 0)]\n\n        bert_method_to_res[(spoil_method, words_amount)].append((bert_score, sub))\n        acc_method_to_res[(spoil_method, words_amount)].append((acc_score, sub))\n        dan_method_to_res[(spoil_method, words_amount)].append((dan_score, sub))\n    \n    assert used_method\n    \n    names = ['accuracy', 'dan_sim', 'bert_sim']\n    scores = [acc_method_to_res, dan_method_to_res, bert_method_to_res]\n    _, axes = plt.subplots(3, 1, figsize=(20, 10))\n    \n    for idx, (name, mapping) in enumerate(zip(names, scores)):\n        subs = None\n        for key, value in mapping.items():\n            if subs is None:\n                subs = [sub for _, sub in value]\n            results = [result for result, _ in value]\n\n            axes[idx].plot(results, label=''.join(key))\n        \n        axes[idx].set_xlable('spoil chars amount')\n        axes[idx].set_ylabel(name)\n        axes[idx].set_title(f'{name} with {method} depending on spoil chars amount')\n        axes[idx].set_xticklabel(subs)\n        axes[idx].legend()\n        axes[idx].grid(True)","metadata":{"_cell_guid":"f5e88d2f-b7ad-41c7-92ad-317ce989ff3d","_uuid":"6eb78e58-b305-48cd-af80-f373d8bb74bf","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}
