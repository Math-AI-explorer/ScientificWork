{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"07105a38-167d-4080-86f1-e28bbc172b85","_uuid":"b7f3779a-a199-4bcc-b86c-6eba030528bd","trusted":true},"source":["### Установка и импорт всех необходимых зависимостей"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"16d1f1be-6c5b-4cf0-af02-3f589e64f949","_uuid":"4b94f1c3-c161-4222-abfa-e3fb66e4880d","collapsed":false,"execution":{"iopub.status.busy":"2023-12-11T23:52:34.777333Z","iopub.status.idle":"2023-12-11T23:52:34.777737Z","shell.execute_reply":"2023-12-11T23:52:34.777547Z","shell.execute_reply.started":"2023-12-11T23:52:34.777523Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["!pip install -q razdel\n","!pip install -q pymorphy2\n","!pip install -q git+https://github.com/ahmados/rusynonyms.git\n","!pip install -q natasha\n","!pip install -q pyaml-env\n","!pip install -q captum"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-12-11T23:52:34.780814Z","iopub.status.idle":"2023-12-11T23:52:34.781340Z","shell.execute_reply":"2023-12-11T23:52:34.781053Z","shell.execute_reply.started":"2023-12-11T23:52:34.781031Z"},"trusted":true},"outputs":[],"source":["import os\n","import sys\n","\n","path_to_alti = '/kaggle/input/transformer-contributions1/transformer-contributions'\n","if not path_to_alti in sys.path:\n","    sys.path.append(path_to_alti)\n","\n","from src.utils_contributions import *\n","from src.contributions import ModelWrapper, ClassificationModelWrapperCaptum, interpret_sentence, occlusion"]},{"cell_type":"code","execution_count":328,"metadata":{"_cell_guid":"e8af1228-dfb5-4d7f-bbf6-d1cb72552c66","_uuid":"11ecb4af-671c-4f65-8913-9c95f7f796bd","collapsed":false,"execution":{"iopub.execute_input":"2023-12-11T23:55:54.929425Z","iopub.status.busy":"2023-12-11T23:55:54.929009Z","iopub.status.idle":"2023-12-11T23:55:54.940027Z","shell.execute_reply":"2023-12-11T23:55:54.939149Z","shell.execute_reply.started":"2023-12-11T23:55:54.929390Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import xml.etree.ElementTree as ET\n","import pandas as pd\n","pd.set_option('display.max_columns', None)\n","\n","import nltk\n","from nltk.corpus import stopwords\n","import re\n","import pymorphy2\n","import razdel\n","import string\n","from natasha import (\n","    MorphVocab,\n","    NewsMorphTagger,\n","    NewsEmbedding,\n","    Segmenter,\n","    NewsSyntaxParser,\n","    Doc\n",")\n","\n","import torch\n","import tensorflow_hub as hub\n","from torch.utils.data import Dataset, DataLoader\n","import transformers\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel, AutoConfig\n","import numpy as np\n","from sklearn.metrics import f1_score\n","\n","from tqdm import tqdm\n","from typing import *\n","from collections import defaultdict\n","from functools import partial\n","from scipy.special import logit\n","\n","from lime.lime_text import LimeTextExplainer\n","import shap\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","rus_stopwords = stopwords.words('russian')\n","punctuation = list(string.punctuation)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"d7cacad4-4f63-43c2-93b1-c9c180bf748d","_uuid":"4351a3ac-2754-4156-96ae-b1866e7f6e82","trusted":true},"source":["### Работа с данными (kaggle)"]},{"cell_type":"code","execution_count":44,"metadata":{"_cell_guid":"19eb260a-7fe2-42e3-ac1e-9657a713481c","_uuid":"5b40ffa6-7032-4f5c-9c17-3cdf66f4a633","collapsed":false,"execution":{"iopub.execute_input":"2023-12-11T20:02:04.700744Z","iopub.status.busy":"2023-12-11T20:02:04.699884Z","iopub.status.idle":"2023-12-11T20:02:04.705784Z","shell.execute_reply":"2023-12-11T20:02:04.704676Z","shell.execute_reply.started":"2023-12-11T20:02:04.700708Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["datasets_folder = '/kaggle/input/sw-datasets/Russian-Sentiment-Analysis-Evaluation-Datasets'\n","datasets = ['SentiRuEval-2015-telecoms', 'SentiRuEval-2015-banks', 'SentiRuEval-2016-banks', 'SentiRuEval-2016-telecoms']\n","samples = ['test.xml', 'train.xml', 'test_etalon.xml']"]},{"cell_type":"code","execution_count":45,"metadata":{"_cell_guid":"10ad2541-7c34-4b11-a6d4-8ef30594e6e0","_uuid":"77e7298c-cf2e-4be8-a178-de925ce239f3","collapsed":false,"execution":{"iopub.execute_input":"2023-12-11T20:02:04.988600Z","iopub.status.busy":"2023-12-11T20:02:04.988283Z","iopub.status.idle":"2023-12-11T20:02:05.925979Z","shell.execute_reply":"2023-12-11T20:02:05.925027Z","shell.execute_reply.started":"2023-12-11T20:02:04.988574Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def extract_data(path: str) -> pd.DataFrame:\n","    \"\"\"\n","    функция для извлечения данных из xml\n","    \"\"\"\n","    tree = ET.parse(path)\n","    root = tree.getroot()\n","    DataFrame = dict()\n","    database = root.findall('database')[0]\n","    DataFrame_columns = list()\n","\n","    for idx, table in enumerate(database.findall('table')):\n","        for column in table.findall('column'):\n","            DataFrame[column.attrib['name']] = list()\n","            DataFrame_columns.append(column.attrib['name'])\n","        if idx == 0:\n","            break\n","\n","    for table in database.findall('table'):\n","        for column in table.findall('column'):\n","            DataFrame[column.attrib['name']].append(column.text)\n","\n","    data = pd.DataFrame(DataFrame, columns=DataFrame_columns)\n","    return data\n","\n","# инициализация всех путей (kaggle)\n","banks_dataset = datasets[2]\n","path2samples = os.path.join(datasets_folder, banks_dataset)\n","banks = ['sberbank', 'vtb', 'gazprom', 'alfabank', 'bankmoskvy', 'raiffeisen', 'uralsib', 'rshb']\n","\n","path2test = os.path.join(path2samples, samples[2])\n","data_test = extract_data(path2test)\n","\n","path2train = os.path.join(path2samples, samples[1])\n","data_train = extract_data(path2train)"]},{"cell_type":"code","execution_count":376,"metadata":{"_cell_guid":"e465b3aa-afb3-4491-ad48-3a8f07c88a7b","_uuid":"7c270cb9-6e6d-44e5-8aa9-5b9a81759385","collapsed":false,"execution":{"iopub.execute_input":"2023-12-12T00:08:53.094371Z","iopub.status.busy":"2023-12-12T00:08:53.093634Z","iopub.status.idle":"2023-12-12T00:09:01.148730Z","shell.execute_reply":"2023-12-12T00:09:01.147573Z","shell.execute_reply.started":"2023-12-12T00:08:53.094334Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def extract_text_features(data: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    функция для первичной обработки текста от лишних символов\n","    \"\"\"\n","    extracted_data = dict()\n","    extracted_data['text'] = list()\n","    extracted_data['0class'] = list()\n","    extracted_data['1class'] = list()\n","\n","    for idx in range(len(data)):\n","        row = data.iloc[idx, :]\n","        banks_review = row[banks]\n","        unique_labels = set(banks_review)\n","        unique_labels.remove('NULL')\n","\n","        # убираем все ненужные знаки\n","        filtered_text = re.sub('http[A-z|:|.|/|0-9]*', '', row['text'])\n","        filtered_text = re.sub('@\\S*', '', filtered_text)\n","        filtered_text = re.sub('#|:|»|«|-|xD|;D|\\\"|_|/', '', filtered_text)\n","        filtered_text = re.sub(r'\\.(?=\\s)|,|(?<!\\s)\\.(?!\\s)', ' ', filtered_text)\n","        filtered_text = re.sub(r'[A-Z]|[a-z]', '', filtered_text)\n","        filtered_text = re.sub(r'\\d+', 'число', filtered_text)\n","        filtered_text = re.sub(r'\\s+', ' ', filtered_text).strip()\n","        new_text = filtered_text\n","\n","        # сохраняем только уникальные токены (без придатка xml NULL)\n","        unique_labels = list(unique_labels)\n","        while len(unique_labels) < 2:\n","            unique_labels.append(unique_labels[-1])\n","        extracted_data['text'].append(new_text)\n","        for idx, label in enumerate(unique_labels):\n","            text_label = int(label) + 1\n","            extracted_data[f'{idx}' + 'class'].append(text_label)\n","\n","    extracted_data = pd.DataFrame(extracted_data)\n","    \n","    # возвращаем dataframe\n","    return extracted_data\n","\n","extracted_val = extract_text_features(data_test)\n","extracted_train = extract_text_features(data_train)"]},{"cell_type":"code","execution_count":381,"metadata":{"_cell_guid":"553036a6-e0cb-4859-9f43-fc8dd418894b","_uuid":"d874a823-0b6d-443d-b0cf-fee72b75b727","collapsed":false,"execution":{"iopub.execute_input":"2023-12-12T00:09:46.429331Z","iopub.status.busy":"2023-12-12T00:09:46.428581Z","iopub.status.idle":"2023-12-12T00:09:46.435734Z","shell.execute_reply":"2023-12-12T00:09:46.434790Z","shell.execute_reply.started":"2023-12-12T00:09:46.429295Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"text/plain":["'Цены на нефть попрежнему остаются на очень низких уровнях РБК НПЗ стремятся отложить импортные…'"]},"execution_count":381,"metadata":{},"output_type":"execute_result"}],"source":["# пример твита из датасета\n","extracted_val.iloc[3308].text"]},{"cell_type":"code","execution_count":382,"metadata":{"_cell_guid":"d6af3578-6851-46ac-81ed-247202502f82","_uuid":"90899eeb-ca26-4010-9d08-888db203f310","collapsed":false,"execution":{"iopub.execute_input":"2023-12-12T00:09:49.594269Z","iopub.status.busy":"2023-12-12T00:09:49.593872Z","iopub.status.idle":"2023-12-12T00:09:49.987061Z","shell.execute_reply":"2023-12-12T00:09:49.986249Z","shell.execute_reply.started":"2023-12-12T00:09:49.594235Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 800x500 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# анализ распределения таргетов на твитах\n","fig, axes = plt.subplots(1, 2, figsize=(8, 5))\n","plt.subplots_adjust(hspace=0.3, wspace=0.5)\n","fontsize=15\n","\n","sns.countplot(data=extracted_train, x='0class', ax=axes[0])\n","axes[0].set_xlabel('class 0', fontsize=fontsize)\n","axes[0].set_ylabel('count', fontsize=fontsize)\n","axes[0].set_xticks([0, 1, 2], ['Neg', 'Neu', 'Pos'], fontsize=fontsize)\n","axes[0].grid(True)\n","\n","sns.countplot(data=extracted_train, x='1class', ax=axes[1])\n","axes[1].set_xlabel('class 1', fontsize=fontsize)\n","axes[1].set_ylabel('count', fontsize=fontsize)\n","axes[1].set_xticks([0, 1, 2], ['Neg', 'Neu', 'Pos'], fontsize=fontsize)\n","axes[1].grid(True)\n","\n","fig.suptitle('target distribution', fontsize=fontsize)\n","\n","None"]},{"cell_type":"markdown","metadata":{"_cell_guid":"84c3b206-9192-44d8-b0c3-99030962fbf1","_uuid":"27a39401-ac18-4df4-b723-57d39d511fb7","trusted":true},"source":["### Инициализируем модель (fine-tune) для решения нашей задачи классификации"]},{"cell_type":"code","execution_count":383,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T00:09:53.473640Z","iopub.status.busy":"2023-12-12T00:09:53.472839Z","iopub.status.idle":"2023-12-12T00:09:53.487750Z","shell.execute_reply":"2023-12-12T00:09:53.486412Z","shell.execute_reply.started":"2023-12-12T00:09:53.473603Z"},"trusted":true},"outputs":[],"source":["fn_model_name = \"DeepPavlov/distilrubert-base-cased-conversational\"\n","\n","class BERTmy(torch.nn.Module):\n","    def __init__(\n","        self, model_name: str, n_classes: int, \n","        use_tok_type_ids: bool, p: float=0.05\n","    ) -> None:\n","        super(BERTmy, self).__init__()\n","        self.rubert = transformers.AutoModel.from_pretrained(\n","            model_name\n","        )\n","        self.tokenizer = transformers.AutoTokenizer.from_pretrained(\n","            model_name, \n","            do_lower_case=True,\n","            add_additional_tokens=True\n","        )\n","        self.use_tok_type_ids = use_tok_type_ids\n","        \n","        hidden_size_output = self.rubert.config.hidden_size\n","        self.pre_classifier = torch.nn.Sequential(\n","            torch.nn.Linear(hidden_size_output, hidden_size_output, bias=True),\n","            torch.nn.Dropout(p),\n","            torch.nn.ReLU()\n","        )\n","        self.classifier = torch.nn.Sequential(\n","            torch.nn.Linear(hidden_size_output, hidden_size_output, bias=True),\n","            torch.nn.Dropout(p),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(hidden_size_output, n_classes),\n","        )\n","\n","    def forward(\n","        self, input_ids: torch.Tensor, attention_mask: torch.Tensor, \n","        token_type_ids: torch.Tensor=None, output_attentions: bool=False,\n","        output_hidden_states: bool=False, return_dict: bool=True\n","    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n","        \n","        input_dict = {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'return_dict': True,\n","            'output_attentions': True,\n","            'output_hidden_states': True\n","        }\n","        if self.use_tok_type_ids and not token_type_ids is None:\n","            input_dict['token_type_ids'] = token_type_ids\n","        \n","        rubert_output = self.rubert(**input_dict)\n","\n","        pooled = rubert_output['last_hidden_state']\n","        attentions = rubert_output['attentions']\n","        hid_states = rubert_output['hidden_states']\n","\n","        output_pre_cls = self.pre_classifier(pooled[:, 0, :])\n","        logits = self.classifier(output_pre_cls)\n","\n","        return {\n","            'logits': logits,\n","            'attentions': attentions,\n","            'hidden_states': hid_states\n","        }"]},{"cell_type":"code","execution_count":384,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T00:09:54.001752Z","iopub.status.busy":"2023-12-12T00:09:54.001003Z","iopub.status.idle":"2023-12-12T00:09:54.008942Z","shell.execute_reply":"2023-12-12T00:09:54.007922Z","shell.execute_reply.started":"2023-12-12T00:09:54.001716Z"},"trusted":true},"outputs":[],"source":["def load_model_hf_cls(\n","    model_load: str, model_type: str, \n","    load_model_weights: bool=False\n",") -> torch.nn.Module:\n","\n","    assert model_type in ['distilbert', 'bert']\n","\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        model_load, do_lower_case=True,\n","        add_additional_tokens=True\n","    )\n","\n","    if load_model_weights:\n","        model = AutoModel.from_pretrained(model_load)\n","        model_config = model.config\n","    else:\n","        model_config = AutoConfig.from_pretrained(model_load)\n","\n","    model_cls = AutoModelForSequenceClassification.from_config(model_config)\n","    \n","    if load_model_weights:\n","        if model_type == 'distilbert':\n","            model_cls.distilbert = model\n","        elif model_type == 'bert':\n","            model_cls.bert = model\n","        del model\n","\n","    return model_cls, tokenizer"]},{"cell_type":"code","execution_count":385,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T00:09:55.253891Z","iopub.status.busy":"2023-12-12T00:09:55.253514Z","iopub.status.idle":"2023-12-12T00:09:59.282153Z","shell.execute_reply":"2023-12-12T00:09:59.280917Z","shell.execute_reply.started":"2023-12-12T00:09:55.253859Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at DeepPavlov/distilrubert-base-cased-conversational were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["distilbert_name = \"DeepPavlov/distilrubert-base-cased-conversational\"\n","bert_base_name = \"DeepPavlov/rubert-base-cased\"\n","\n","device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","num_cls = len(pd.unique(extracted_train['0class']))\n","load_tf = True\n","\n","if load_tf:\n","    model_cls, tokenizer = load_model_hf_cls(\n","        distilbert_name, model_type='distilbert', \n","        load_model_weights=True\n","    )\n","    seq_max_len = model_cls.config.max_position_embeddings\n","    hid_dim = model_cls.config.dim\n","    model_cls.dropout = torch.nn.Identity()\n","    model_cls.pre_classifier = torch.nn.Sequential(\n","        torch.nn.Linear(hid_dim, hid_dim, bias=False),\n","        torch.nn.Dropout(0.15),\n","        torch.nn.ReLU()\n","    )\n","    model_cls.classifier = torch.nn.Sequential(\n","        torch.nn.Linear(hid_dim, hid_dim, bias=False),\n","        torch.nn.Dropout(0.15),\n","        torch.nn.ReLU(),\n","        torch.nn.Linear(hid_dim, num_cls, bias=False),\n","    )\n","else:\n","    model_cls = BERTmy(model_name=distilbert_name, n_classes=num_cls, use_tok_type_ids=False)\n","    tokenizer = model_cls.tokenizer\n","    seq_max_len = model_cls.rubert.config.max_position_embeddings"]},{"cell_type":"markdown","metadata":{"_cell_guid":"a021a9f9-44ed-42a5-84c6-848e064b38a7","_uuid":"46a83749-640d-4bd6-9be0-7623bc16c690","trusted":true},"source":["### Инициализируем class для нашего датасета"]},{"cell_type":"code","execution_count":387,"metadata":{"_cell_guid":"4fe85b1d-d8b2-4be9-8b4e-dde97c2a4d42","_uuid":"9ba9fdee-22c8-4555-a26c-0bcec67ca8a9","collapsed":false,"execution":{"iopub.execute_input":"2023-12-12T00:10:01.462406Z","iopub.status.busy":"2023-12-12T00:10:01.461980Z","iopub.status.idle":"2023-12-12T00:10:01.470470Z","shell.execute_reply":"2023-12-12T00:10:01.469472Z","shell.execute_reply.started":"2023-12-12T00:10:01.462370Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["train_batch_size = 24\n","val_batch_size = 24\n","\n","class SentimentDataTransformer(Dataset):\n","    # инициализация датасета\n","    def __init__(\n","        self, texts: List[str], \n","        labels: List[Tuple[int, ...]]=None\n","    ) -> None:\n","        \n","        self.texts = texts\n","        self.labels = labels\n","\n","    # для получения размера датасета\n","    def __len__(self) -> int:\n","        return len(self.texts)\n","\n","    # для получения элемента по индексу\n","    def __getitem__(\n","        self, index: int\n","    ) -> Tuple[Union[str, int]]:\n","\n","        if self.labels is None:\n","            return self.texts[index]\n","\n","        text = self.texts[index]\n","        labels = self.labels[index]\n","        \n","        target1, target2 = labels\n","\n","        return text, target1, target2"]},{"cell_type":"code","execution_count":388,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T00:10:01.793780Z","iopub.status.busy":"2023-12-12T00:10:01.793048Z","iopub.status.idle":"2023-12-12T00:10:01.801208Z","shell.execute_reply":"2023-12-12T00:10:01.800137Z","shell.execute_reply.started":"2023-12-12T00:10:01.793750Z"},"trusted":true},"outputs":[],"source":["class collate_fn_transformers():\n","    \n","    def __init__(\n","        self, tokenizer: AutoTokenizer, \n","        use_labels:bool, use_tok_type_ids: bool\n","    ) -> None:\n","        \n","        self.tokenizer = tokenizer\n","        self.use_tok_type_ids = use_tok_type_ids\n","        self.use_labels = use_labels\n","        \n","    def __call__(self, batch):\n","        \n","        if not self.use_labels:\n","\n","            texts = batch\n","\n","            return self.tokenizer(\n","                texts, #truncation=True,\n","                padding=True, add_special_tokens=True,\n","                return_token_type_ids=self.use_tok_type_ids,\n","                return_tensors='pt'\n","            )\n","        \n","        texts, target1, target2 = zip(*batch)\n","        \n","        input_ids = self.tokenizer(\n","            texts, #truncation=True,\n","            padding=True, add_special_tokens=True,\n","            return_token_type_ids=self.use_tok_type_ids,\n","            return_tensors='pt'\n","        )\n","        target1 = torch.tensor(target1)\n","        target2 = torch.tensor(target2)\n","        \n","        return input_ids, target1, target2"]},{"cell_type":"markdown","metadata":{"_cell_guid":"ec214cce-6c71-4987-b673-f4f59b6e29f2","_uuid":"d72254d0-e70d-443a-9506-34554ec96efe","trusted":true},"source":["### Инициализируем наши DataLoaders"]},{"cell_type":"code","execution_count":389,"metadata":{"_cell_guid":"b5110fba-0208-4967-90fb-04bc71a68957","_uuid":"be40ab48-96e2-4c10-af39-36066c75dfc4","collapsed":false,"execution":{"iopub.execute_input":"2023-12-12T00:10:02.766186Z","iopub.status.busy":"2023-12-12T00:10:02.765359Z","iopub.status.idle":"2023-12-12T00:10:02.780756Z","shell.execute_reply":"2023-12-12T00:10:02.779793Z","shell.execute_reply.started":"2023-12-12T00:10:02.766145Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["train = SentimentDataTransformer(\n","    texts=extracted_train['text'].tolist(),\n","    labels=list(zip(extracted_train['0class'], extracted_train['1class']))\n",")\n","\n","val = SentimentDataTransformer(\n","    texts=extracted_val['text'].tolist(),\n","    labels=list(zip(extracted_val['0class'], extracted_val['1class']))\n",")\n","\n","train_loader = DataLoader(\n","    train, batch_size=train_batch_size, shuffle=True,\n","    collate_fn=collate_fn_transformers(tokenizer=tokenizer, use_tok_type_ids=False, use_labels=True)\n",")\n","val_loader = DataLoader(\n","    val, batch_size=val_batch_size, shuffle=False,\n","    collate_fn=collate_fn_transformers(tokenizer=tokenizer, use_tok_type_ids=False, use_labels=True)\n",")\n","loaders = {\n","    'train': train_loader,\n","    'val': val_loader\n","}"]},{"cell_type":"markdown","metadata":{"_cell_guid":"f4164662-55b5-43d0-ad49-7c57ea8eb62c","_uuid":"6c111c3b-95c7-4dc8-ba88-8f8bbce229dd","trusted":true},"source":["### Дообучение модели"]},{"cell_type":"code","execution_count":390,"metadata":{"_cell_guid":"8ab49c8f-c3fa-4786-a63b-fe6708927100","_uuid":"c349e8e4-a562-4927-aaa2-ac14f5dcf8df","collapsed":false,"execution":{"iopub.execute_input":"2023-12-12T00:10:03.601990Z","iopub.status.busy":"2023-12-12T00:10:03.601587Z","iopub.status.idle":"2023-12-12T00:10:03.628227Z","shell.execute_reply":"2023-12-12T00:10:03.627081Z","shell.execute_reply.started":"2023-12-12T00:10:03.601961Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def train_model(\n","    epochs: int, model: torch.nn.Module, loaders: Dict[str, DataLoader], \n","    optimizer: torch.optim, scheduler: torch.optim.lr_scheduler, \n","    weights_vector: torch.tensor=None, device: str='cpu'\n",") -> None:\n","    # cross entropy loss\n","    model = model.to(device)\n","    if weights_vector is None:\n","        weights_vector = torch.ones(size=(num_cls,), device=device)\n","    loss_function1 = torch.nn.CrossEntropyLoss(reduction='mean', weight=weights_vector)\n","    loss_function2 = torch.nn.CrossEntropyLoss(reduction='mean', weight=weights_vector)\n","    \n","    # извлечение DataLoaders\n","    if len(loaders) > 1:\n","        train_loader = loaders['train']\n","        val_loader = loaders['val']\n","        steps_per_epoch = [('train', train_loader), ('val', val_loader)]\n","    else:\n","        train_loader = loaders['train']\n","        steps_per_epoch = [('train', train_loader)]\n","\n","    # обучение по эпохам\n","    for epoch in range(epochs):\n","        for mode, loader in steps_per_epoch:\n","            # сохранение статистик\n","            train_loss = 0\n","            n_correct = 0\n","            processed_data = 0\n","            \n","            # train/val \n","            if mode == 'train':\n","                model.train()\n","                requires_grad_mode = True\n","            else:\n","                model.eval()\n","                requires_grad_mode = False\n","            \n","            # проход по батчам\n","            for inputs, trg1, trg2 in tqdm(loader):\n","                # обнуляем градиенты\n","                optimizer.zero_grad()\n","\n","                # извлечение входных данных для модели\n","                for key, value in inputs.items():\n","                    inputs[key] = value.to(device)\n","                trg1, trg2 = trg1.to(device), trg2.to(device)\n","                inputs['return_dict'] = True\n","                \n","                # устанавливаем необходимость вычислять/не_вычислять градиенты\n","                with torch.set_grad_enabled(requires_grad_mode):\n","                    outputs = model(**inputs)\n","                    preds = torch.argmax(outputs['logits'], dim=1)\n","\n","                    # настраиваем модели на конкретный target\n","                    if all(trg1 == trg2):\n","                        loss1 = loss_function1(outputs['logits'], trg1)\n","                        train_loss += loss1.item()\n","                        n_correct += torch.sum(preds == trg1).cpu().detach().numpy()\n","                        if mode == 'train':\n","                            # вычисляем градиенты и обновляем веса\n","                            loss1.backward()\n","                            optimizer.step()\n","                    # если у твита более чем 1 метка, то настраиваем на обе\n","                    else:\n","                        loss1 = loss_function1(outputs['logits'], trg1) * 0.5\n","                        loss2 = loss_function2(outputs['logits'], trg2) * 0.5\n","                        loss_all = loss1 + loss2\n","                        train_loss += loss_all.item()\n","\n","                        mask_singular = trg1 == trg2\n","                        mask_multiple = trg1 != trg2\n","                        singular = preds[mask_singular]\n","                        n_correct += torch.sum(\n","                            singular == trg1[mask_singular]\n","                        ).cpu().detach().numpy()\n","                        multiple = preds[mask_multiple]\n","                        n_correct += torch.sum(\n","                            (multiple == trg1[mask_multiple]) | (multiple == trg2[mask_multiple])\n","                        ).cpu().detach().numpy()\n","                        if mode == 'train':\n","                            # вычисляем градиенты и обновляем веса\n","                            loss_all.backward()\n","                            optimizer.step()\n","\n","                    processed_data += len(preds)\n","\n","            # вычисляем ошибку и точность прогноза на эпохе\n","            loader_loss = train_loss / processed_data\n","            loader_acc = n_correct / processed_data\n","            print(f'{epoch + 1} epoch with {mode} mode has: {loader_loss} loss, {loader_acc} acc')\n","        \n","        # делаем шаг для sheduler оптимайзера\n","        scheduler.step()"]},{"cell_type":"code","execution_count":391,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T00:10:09.404161Z","iopub.status.busy":"2023-12-12T00:10:09.403138Z","iopub.status.idle":"2023-12-12T00:10:11.669661Z","shell.execute_reply":"2023-12-12T00:10:11.668439Z","shell.execute_reply.started":"2023-12-12T00:10:09.404098Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/392 [00:00<?, ?it/s]\u001b[A\n","  1%|          | 3/392 [00:00<00:16, 22.92it/s]\u001b[A\n","  2%|▏         | 6/392 [00:00<00:16, 23.54it/s]\u001b[A\n","  2%|▏         | 9/392 [00:00<00:16, 23.71it/s]\u001b[A\n","  3%|▎         | 12/392 [00:00<00:16, 23.75it/s]\u001b[A\n","  4%|▍         | 15/392 [00:00<00:15, 23.70it/s]\u001b[A\n","  5%|▍         | 18/392 [00:00<00:15, 23.65it/s]\u001b[A\n","  5%|▌         | 21/392 [00:00<00:15, 24.13it/s]\u001b[A\n","  6%|▌         | 24/392 [00:01<00:15, 24.44it/s]\u001b[A\n","  7%|▋         | 27/392 [00:01<00:15, 23.98it/s]\u001b[A\n","  8%|▊         | 30/392 [00:01<00:14, 25.14it/s]\u001b[A\n","  8%|▊         | 33/392 [00:01<00:14, 24.68it/s]\u001b[A\n","  9%|▉         | 36/392 [00:01<00:14, 23.98it/s]\u001b[A\n"," 10%|▉         | 39/392 [00:01<00:14, 23.78it/s]\u001b[A\n"," 11%|█         | 42/392 [00:01<00:14, 24.64it/s]\u001b[A\n"," 12%|█▏        | 47/392 [00:01<00:14, 23.85it/s]\u001b[A\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">17</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>{<span style=\"color: #808000; text-decoration-color: #808000\">'params'</span>: model_cls.classifier.parameters(), <span style=\"color: #808000; text-decoration-color: #808000\">'lr'</span>: <span style=\"color: #0000ff; text-decoration-color: #0000ff\">8e-4</span>}                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span>], lr=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1e-6</span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span>scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.95</span>)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>17 train_model(epochs, model_cls, loaders, optimizer, scheduler, weights_vector, device)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_model</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">45</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">42 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">43 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># извлечение входных данных для модели</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> key, value <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> inputs.items():                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>45 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>inputs[key] = value.to(device)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">46 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>trg1, trg2 = trg1.to(device), trg2.to(device)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">47 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>inputs[<span style=\"color: #808000; text-decoration-color: #808000\">'return_dict'</span>] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n","</pre>\n"],"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m17\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   \u001b[0m{\u001b[33m'\u001b[0m\u001b[33mparams\u001b[0m\u001b[33m'\u001b[0m: model_cls.classifier.parameters(), \u001b[33m'\u001b[0m\u001b[33mlr\u001b[0m\u001b[33m'\u001b[0m: \u001b[94m8e-4\u001b[0m}                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m], lr=\u001b[94m1e-6\u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0mscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=\u001b[94m0.95\u001b[0m)                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m17 train_model(epochs, model_cls, loaders, optimizer, scheduler, weights_vector, device)       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mtrain_model\u001b[0m:\u001b[94m45\u001b[0m                                                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# извлечение входных данных для модели\u001b[0m                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m key, value \u001b[95min\u001b[0m inputs.items():                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m45 \u001b[2m│   │   │   │   │   \u001b[0minputs[key] = value.to(device)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtrg1, trg2 = trg1.to(device), trg2.to(device)                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs[\u001b[33m'\u001b[0m\u001b[33mreturn_dict\u001b[0m\u001b[33m'\u001b[0m] = \u001b[94mTrue\u001b[0m                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mKeyboardInterrupt\u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["# weigths for classes\n","weights_vector = torch.zeros(size=(num_cls,), device=device)\n","unique_labels, counts = np.unique(\n","    extracted_train['0class'], return_counts=True\n",")\n","sm_count = np.sum(counts)\n","for label, count in zip(unique_labels, counts):\n","    weights_vector[label] = 1 - count/sm_count\n","\n","# train model\n","epochs = 15\n","optimizer = torch.optim.Adam([\n","    {'params': model_cls.pre_classifier.parameters(), 'lr': 8e-4},\n","    {'params': model_cls.classifier.parameters(), 'lr': 8e-4}\n","], lr=1e-6)\n","scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n","train_model(epochs, model_cls, loaders, optimizer, scheduler, weights_vector, device)"]},{"cell_type":"code","execution_count":57,"metadata":{"_cell_guid":"2fa670b4-8330-4a79-ac62-d867928544f9","_uuid":"19503e86-4d81-4fd8-8a6e-f0f6f9891405","collapsed":false,"execution":{"iopub.execute_input":"2023-12-11T20:02:26.963836Z","iopub.status.busy":"2023-12-11T20:02:26.963455Z","iopub.status.idle":"2023-12-11T20:02:33.173962Z","shell.execute_reply":"2023-12-11T20:02:33.173158Z","shell.execute_reply.started":"2023-12-11T20:02:26.963805Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Load weights? (y/n) y\n"]}],"source":["model_name = 'distilbert_cls.pth'\n","\n","mode_process = input('Load weights? (y/n)')\n","if mode_process == 'n':\n","    torch.save(model_cls.state_dict(), model_name)\n","elif mode_process == 'y':\n","    model_cls.load_state_dict(torch.load('/kaggle/input/distilbert-w3/distilbert_cls.pth'))\n","else:\n","    assert mode_process in ['n', 'y']\n","model_cls.eval()\n","None"]},{"cell_type":"markdown","metadata":{"_cell_guid":"114d3f5e-6292-4964-8e88-7ed63b57100a","_uuid":"ed44b641-9164-4946-ac60-777b1b4afb6c","trusted":true},"source":["### Вычисление итоговых показателей"]},{"cell_type":"code","execution_count":58,"metadata":{"_cell_guid":"26fee109-eaec-4b0f-a90d-a4d72ea6a9e1","_uuid":"ca969426-e888-4d62-ad59-39920e55edec","collapsed":false,"execution":{"iopub.execute_input":"2023-12-11T20:02:34.175723Z","iopub.status.busy":"2023-12-11T20:02:34.175332Z","iopub.status.idle":"2023-12-11T20:02:34.190717Z","shell.execute_reply":"2023-12-11T20:02:34.189725Z","shell.execute_reply.started":"2023-12-11T20:02:34.175692Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def calculate_accuracy(\n","    model: torch.nn.Module, loader: DataLoader,\n","    device: str='cpu'\n",") -> float:\n","    model.eval()\n","    model = model.to(device)\n","    n_correct = 0\n","    processed_data = 0\n","    \n","    # проход по батчам\n","    for inputs, trg1, trg2 in tqdm(loader):\n","\n","        # извлечение входных данных для модели\n","        for key, value in inputs.items():\n","            inputs[key] = value.to(device)\n","        trg1, trg2 = trg1.to(device), trg2.to(device)\n","        inputs['return_dict'] = True\n","        \n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","            preds = torch.argmax(outputs['logits'], dim=1)\n","            mask_singular = trg1 == trg2\n","            mask_multiple = trg1 != trg2\n","            singular = preds[mask_singular]\n","            n_correct += torch.sum(\n","                singular == trg1[mask_singular]\n","            ).cpu().detach().numpy()\n","            multiple = preds[mask_multiple]\n","            if len(multiple) > 0:\n","                n_correct += torch.sum(\n","                    (multiple == trg1[mask_multiple]) | (multiple == trg2[mask_multiple])\n","                ).cpu().detach().numpy()\n","\n","            processed_data += len(preds)\n","        \n","    loader_acc = n_correct / processed_data\n","    \n","    return loader_acc\n","\n","def calculate_f1_class(\n","    model: torch.nn.Module, loader: DataLoader,\n","    class_num: int, device: str='cpu'\n",") -> float:\n","    model.eval()\n","    model = model.to(device)\n","    all_preds = list()\n","    groud_truth = list()\n","    \n","    # проход по батчам\n","    for inputs, trg1, trg2 in tqdm(loader):\n","\n","        # извлечение входных данных для модели\n","        for key, value in inputs.items():\n","            inputs[key] = value.to(device)\n","        inputs['return_dict'] = True\n","        \n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","            \n","            preds = torch.argmax(\n","                outputs['logits'], dim=1\n","            ).cpu().numpy()\n","            all_preds.append(preds)\n","            groud_truth.append(trg1.cpu().detach().numpy())\n","\n","    all_preds = np.hstack(all_preds)\n","    groud_truth = np.hstack(groud_truth)\n","    mask = all_preds == class_num\n","    all_preds[mask] = 1\n","    all_preds[~mask] = 0\n","    mask = groud_truth == class_num\n","    groud_truth[mask] = 1\n","    groud_truth[~mask] = 0\n","    \n","    return f1_score(groud_truth, all_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_acc = calculate_accuracy(model_cls, val_loader, device)\n","class_neg_f1 = calculate_f1_class(model_cls, val_loader, 0, device)\n","class_neu_f1 = calculate_f1_class(model_cls, val_loader, 1, device)\n","class_pos_f1 = calculate_f1_class(model_cls, val_loader, 2, device)"]},{"cell_type":"code","execution_count":104,"metadata":{"_cell_guid":"82265fd8-c0bd-44d7-b9d8-aca69d404cb0","_uuid":"9b2b22cf-e842-40f4-b450-2dd7bf72d097","collapsed":false,"execution":{"iopub.execute_input":"2023-12-11T19:13:53.079968Z","iopub.status.busy":"2023-12-11T19:13:53.079566Z","iopub.status.idle":"2023-12-11T19:13:53.087779Z","shell.execute_reply":"2023-12-11T19:13:53.085988Z","shell.execute_reply.started":"2023-12-11T19:13:53.079934Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"text/plain":["(0.748566254150317, 0.6687078995713411, 0.8177156177156177, 0.512091038406828)"]},"execution_count":104,"metadata":{},"output_type":"execute_result"}],"source":["# общая accuracy и f1 по классам\n","test_acc, class_neg_f1, class_neu_f1, class_pos_f1"]},{"cell_type":"markdown","metadata":{"_cell_guid":"8882bdef-e71a-4445-8823-c6cd3ac91816","_uuid":"cac0e4f4-82dd-4140-9443-c4539d51a316","trusted":true},"source":["## Backdoor attacks on neural network(adversial examples)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"c7a5f905-6e00-430b-a6b1-a9cb1ea55c89","_uuid":"2def7913-246a-4e98-8733-7579e3d96e4c","trusted":true},"source":["### USE metric for similarity between original sentence and spoiled sentence"]},{"cell_type":"code","execution_count":61,"metadata":{"_cell_guid":"a2237584-a021-4633-a333-8413f2555a5f","_uuid":"e5c67eb2-846d-4e5e-aaf4-57493cfc825b","collapsed":false,"execution":{"iopub.execute_input":"2023-12-11T20:02:49.142291Z","iopub.status.busy":"2023-12-11T20:02:49.141305Z","iopub.status.idle":"2023-12-11T20:02:49.154257Z","shell.execute_reply":"2023-12-11T20:02:49.153319Z","shell.execute_reply.started":"2023-12-11T20:02:49.142253Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def use_score(original, adversial, use_bert_encoder=False, model=None):\n","    from scipy.spatial.distance import cosine\n","    # Load pre-trained universal sentence encoder model\n","    if not use_bert_encoder:\n","        # using DAN from tensorflow\n","        use_encoder = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n","\n","        sentences_orig = list()\n","        sentences_adv = list()\n","        for pair in zip(original, adversial):\n","            orig, adv = pair\n","            sentences_orig.append(orig)\n","            sentences_adv.append(adv)\n","\n","        # get embs of texts\n","        sentences_orig_emb = use_encoder(sentences_orig)\n","        sentences_adv_emb = use_encoder(sentences_adv)\n","\n","        # calculate use_score with DAN\n","        use_scores = list()\n","        for pair in zip(sentences_orig_emb, sentences_adv_emb):\n","            orig_emb, adv_emb = pair[0], pair[1]\n","            use_score_one = 1 - cosine(orig_emb, adv_emb)\n","            use_scores.append(use_score_one)\n","    else:\n","        # using BERT itself\n","        def get_inputs(text): # get inputs for model\n","            inputs = model.tokenizer(\n","                text, padding=True, \n","                add_special_tokens=True, \n","                return_tensors='pt'\n","            )\n","            ids = inputs['input_ids'].type(torch.long).to(device)\n","            mask = inputs['attention_mask'].type(torch.long).to(device)\n","            token_type_ids = inputs[\"token_type_ids\"].type(torch.long).to(device)\n","            \n","            return ids, mask, token_type_ids\n","\n","        # calculate use_score with BERT\n","        use_scores = list()\n","        for pair in zip(original, adversial):\n","            orig, adv = pair[0], pair[1]\n","            orig_inputs = get_inputs(orig)\n","            adv_inputs = get_inputs(adv)\n","            orig_outputs = model.rubert(*orig_inputs)\n","            adv_outputs = model.rubert(*adv_inputs)\n","            orig_pooled, adv_pooled = orig_outputs[1], adv_outputs[1]\n","            orig_pooled = orig_pooled.cpu().detach().numpy()\n","            adv_pooled = adv_pooled.cpu().detach().numpy()\n","            use_score_one = 1 - cosine(orig_pooled, adv_pooled)\n","            use_scores.append(use_score_one)\n","    \n","    return use_scores, np.mean(use_scores)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"2fd87276-d681-4aa6-8cc4-d5824c8f3642","_uuid":"fdf759b2-374a-4203-892d-13259da64f14","trusted":true},"source":["### Attention visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3c4968e-a083-4284-a5c4-0b88a9592f00","_uuid":"733e2079-83b7-4298-9626-9e7575f915a9","collapsed":false,"execution":{"iopub.execute_input":"2023-12-10T13:00:33.492761Z","iopub.status.busy":"2023-12-10T13:00:33.492386Z","iopub.status.idle":"2023-12-10T13:00:33.501011Z","shell.execute_reply":"2023-12-10T13:00:33.499949Z","shell.execute_reply.started":"2023-12-10T13:00:33.492731Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def visualize_attention_one_head(tokens, attention_weights, num_layer, num_head):\n","    # works only with batch_size=1\n","    num_layer -= 1\n","    num_head -= 1\n","    assert num_head >= 0 and num_head < len(attention_weights[0][0])\n","    assert num_layer < len(attention_weights) and num_layer >= 0\n","    \n","    attention_layer = attention_weights[num_layer][0].cpu().detach().numpy()\n","    \n","    fig, ax = plt.subplots(1, 1, figsize=(9, 6))\n","\n","    g = sns.heatmap(attention_layer[num_head], annot=True, linewidth=0.1, fmt='.1g')\n","    # xlabel='weight_for_embed', ylabel='num_embed'\n","    g.set(title=f'layer: {num_layer + 1}; head: {num_head + 1} attention map')\n","    tickvalues = range(0,len(tokens) + 2)\n","    tokens = ['CLS'] + tokens + ['SEP']\n","    g.set_yticks(ticks=tickvalues ,labels=tokens, rotation='horizontal')\n","    g.set_xticks(ticks=tickvalues ,labels=tokens, rotation='vertical')\n","    ax = g\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"63054f35-5904-4e39-8871-37b2cfaf13ac","_uuid":"12f060c2-107c-4121-b231-a4079561b10c","collapsed":false,"execution":{"iopub.execute_input":"2023-12-10T13:00:33.855379Z","iopub.status.busy":"2023-12-10T13:00:33.854689Z","iopub.status.idle":"2023-12-10T13:00:33.916219Z","shell.execute_reply":"2023-12-10T13:00:33.915211Z","shell.execute_reply.started":"2023-12-10T13:00:33.855345Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["adversial_examples_char = pd.read_csv('/kaggle/input/result-data/adversial_examples_char.csv')\n","text_example = extracted_val.iloc[10].text\n","text_example_ins = adversial_examples_char['1_ins_amount_1_SpoiledText'].iloc[10]\n","text_example_del = adversial_examples_char['1_del_amount_1_SpoiledText'].iloc[10]\n","text_example_sub = adversial_examples_char['1_sub_amount_1_SpoiledText'].iloc[10]"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ede9ac5a-c196-4cc1-b7c5-0ed241060268","_uuid":"52147ee1-2a73-4137-bd24-a043e4911b09","collapsed":false,"execution":{"iopub.execute_input":"2023-12-09T17:56:55.894998Z","iopub.status.busy":"2023-12-09T17:56:55.894597Z","iopub.status.idle":"2023-12-09T17:56:55.900762Z","shell.execute_reply":"2023-12-09T17:56:55.899813Z","shell.execute_reply.started":"2023-12-09T17:56:55.894967Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def visualize_attention_for_text(text, num_layer, num_head):\n","    text_seq = bert.tokenizer(\n","        text,\n","        padding=True,\n","        add_special_tokens=True,\n","        return_tensors='pt'\n","    ).to(device)\n","    logits, attention = bert(**text_seq, output_attentions=True)\n","    tokens = bert.tokenizer.tokenize(text)\n","    visualize_attention_one_head(tokens, attention, num_layer, num_head)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3c3b0df9-45ac-49e2-84d7-f4241dd80267","_uuid":"8c67df3a-86ce-4bf6-b915-49ec30ea8c11","collapsed":false,"execution":{"iopub.execute_input":"2023-12-04T23:18:15.793690Z","iopub.status.busy":"2023-12-04T23:18:15.793315Z","iopub.status.idle":"2023-12-04T23:18:16.475574Z","shell.execute_reply":"2023-12-04T23:18:16.474547Z","shell.execute_reply.started":"2023-12-04T23:18:15.793657Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["visualize_attention_for_text(text_example_sub, 12, 1)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"c843d9f5-bff2-4a42-a9a0-6c0ee9d461c4","_uuid":"3f317f59-a082-4c84-a625-6a96ed49979c","trusted":true},"source":["### utils for generating adversarial text"]},{"cell_type":"code","execution_count":62,"metadata":{"_cell_guid":"273f1cd4-10e9-4c45-b3b7-e8da3516c7e5","_uuid":"8ea101b3-c750-46ed-8dfe-10aee7384980","collapsed":false,"execution":{"iopub.execute_input":"2023-12-11T20:02:52.852719Z","iopub.status.busy":"2023-12-11T20:02:52.852357Z","iopub.status.idle":"2023-12-11T20:02:52.866156Z","shell.execute_reply":"2023-12-11T20:02:52.865171Z","shell.execute_reply.started":"2023-12-11T20:02:52.852690Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["key_errors = {\n","    'й': ['ц', 'ы', 'ф'],\n","    'ц': ['й', 'ы', 'у'],\n","    'у': ['ц', 'в', 'к'],\n","    'к': ['у', 'а', 'е'],\n","    'е': ['к', 'п', 'н'],\n","    'н': ['е', 'р', 'г'],\n","    'г': ['н', 'о', 'ш'],\n","    'ш': ['г', 'л', 'щ'],\n","    'щ': ['ш', 'д', 'з'],\n","    'з': ['щ', 'ж'],\n","    'х': ['ъ', 'э', 'з'],\n","    'ъ': ['э', 'х'],\n","    'ф': ['й', 'ы', 'я'],\n","    'ы': ['ц', 'в', 'ч', 'ф'],\n","    'в': ['у', 'а', 'с', 'ы'],\n","    'а': ['к', 'п', 'м', 'в'],\n","    'п': ['е', 'р', 'и', 'а'],\n","    'р': ['н', 'о', 'т', 'п'],\n","    'о': ['г', 'л', 'ь', 'р'],\n","    'л': ['ш', 'д', 'б', 'о'],\n","    'д': ['щ', 'ж', 'ю', 'л', 'б'],\n","    'ж': ['з', 'э', 'ю', 'д'],\n","    'э': ['х', 'ъ', 'ж'],\n","    'я': ['ф', 'ы', 'ч'],\n","    'ч': ['ы', 'в', 'с', 'я'],\n","    'с': ['в', 'а', 'м', 'ч'],\n","    'м': ['а', 'п', 'и', 'с'],\n","    'и': ['п', 'р', 'т', 'м'],\n","    'т': ['р', 'о', 'ь', 'и'],\n","    'ь': ['о', 'л', 'б', 'т'],\n","    'б': ['ь', 'л', 'д', 'ю'],\n","    'ю': ['д', 'ж', 'б'],\n","    'r': ['t', 'f', 'e'],\n","    't': ['y', 'f', 'e'],\n","    '0': ['9', '-'],\n","    '1': ['`', '2'],\n","    '2': ['1', '3'],\n","    '3': ['2', '4'],\n","    '4': ['3', '5'],\n","    '5': ['4', '6'],\n","    '6': ['5', '7'],\n","    '7': ['6', '8'],\n","    '8': ['7', '9'],\n","    '9': ['8', '0'],\n","    '-': ['0', '+'],\n","    'k': ['i', 'j', 'l', 'm'],\n","    '.': [',', '/', 'l', ';']\n","}\n","# получаем словарь формата: буква -> ближайшие буквы на клавиатуре"]},{"cell_type":"markdown","metadata":{},"source":["### Prepare data for adversarial generating"]},{"cell_type":"code","execution_count":63,"metadata":{"_cell_guid":"0dd827a1-3317-4285-9dab-79b4e96d78c8","_uuid":"da7eac17-3985-45b6-b1c5-8c0ff4a8950c","collapsed":false,"execution":{"iopub.execute_input":"2023-12-11T20:02:53.279849Z","iopub.status.busy":"2023-12-11T20:02:53.279448Z","iopub.status.idle":"2023-12-11T20:02:53.293571Z","shell.execute_reply":"2023-12-11T20:02:53.292565Z","shell.execute_reply.started":"2023-12-11T20:02:53.279816Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Размер текста для генерации:  2120\n","Баланс классов: \n","(array([0, 1, 2]), array([ 550, 1300,  270]))\n"]}],"source":["# выбираем текст для генерации состязательных примеров с сохранением исходной пропорции\n","limit_neu = 1300\n","limit_pos = 270\n","limit_neg = 550\n","adversial_examples_pos = extracted_val[extracted_val['0class'] == 2]\n","adversial_examples_neu = extracted_val[extracted_val['0class'] == 1]\n","adversial_examples_neg = extracted_val[extracted_val['0class'] == 0]\n","\n","adversial_examples_pos = adversial_examples_pos.head(limit_pos)\n","adversial_examples_neu = adversial_examples_neu.head(limit_neu)\n","adversial_examples_neg = adversial_examples_neg.head(limit_neg)\n","\n","adversial_examples = pd.concat([adversial_examples_pos, adversial_examples_neu, adversial_examples_neg])\n","adversial_examples_char = adversial_examples.sample(frac=1)\n","\n","print('Размер текста для генерации: ', len(adversial_examples_char))\n","print('Баланс классов: ')\n","print(np.unique(adversial_examples_char['0class'], return_counts=True))"]},{"cell_type":"markdown","metadata":{},"source":["## Work with word importance"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T20:03:31.196312Z","iopub.status.busy":"2023-12-11T20:03:31.195907Z","iopub.status.idle":"2023-12-11T20:03:31.203564Z","shell.execute_reply":"2023-12-11T20:03:31.202538Z","shell.execute_reply.started":"2023-12-11T20:03:31.196278Z"},"trusted":true},"outputs":[],"source":["def gather_back_tokens(tokens: List[str], tokens_type: str) -> str:\n","    \"\"\"\n","    для превращения токенов в предложение\n","    tokens: список токенов\n","    tokens_type: natasha или razdel\n","    \"\"\"\n","    assert tokens_type in ['razdel', 'natasha']\n","\n","    sent = ''\n","    prev_end = None\n","    for token in tokens:\n","\n","        if tokens_type == 'natasha':\n","            token_text = token['text']\n","            token_start, token_stop = token['start'], token['stop']\n","        else:\n","            token_text = token.text\n","            token_start, token_stop = token.start, token.stop\n","        \n","        if not prev_end is None:\n","            sent += (token_start - prev_end) * ' '\n","\n","        sent += token_text\n","        prev_end = token_stop\n"," \n","    return sent"]},{"cell_type":"code","execution_count":193,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T22:54:43.726578Z","iopub.status.busy":"2023-12-11T22:54:43.726172Z","iopub.status.idle":"2023-12-11T22:54:43.734400Z","shell.execute_reply":"2023-12-11T22:54:43.733532Z","shell.execute_reply.started":"2023-12-11T22:54:43.726547Z"},"trusted":true},"outputs":[],"source":["model_cls.eval()\n","model_cls = model_cls.to(device)"]},{"cell_type":"code","execution_count":262,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T23:30:51.391796Z","iopub.status.busy":"2023-12-11T23:30:51.391340Z","iopub.status.idle":"2023-12-11T23:30:51.400950Z","shell.execute_reply":"2023-12-11T23:30:51.399908Z","shell.execute_reply.started":"2023-12-11T23:30:51.391764Z"},"trusted":true},"outputs":[],"source":["def predict_texts(texts: List[str], func_type: str):\n","    \"\"\"\n","    for Lime: return probability distribution of text\n","    \"\"\"\n","    assert func_type in ['shap', 'lime']\n","    \n","    if func_type == 'shap':\n","        texts = list(map(lambda x: re.sub(r'\\.{3}', '[MASK]', x), texts))\n","\n","    # get model outputs\n","    dataset = SentimentDataTransformer(texts=texts)\n","    dataloader = DataLoader(\n","        dataset, batch_size=30, shuffle=False,\n","        collate_fn=collate_fn_transformers(\n","            tokenizer=tokenizer, use_labels=False,\n","            use_tok_type_ids=False\n","        )\n","    )\n","    all_probs = list()\n","\n","    for batch in dataloader:\n","        for key, value in batch.items():\n","            batch[key] = value.to(device)\n","        batch['return_dict'] = True\n","\n","        with torch.no_grad():\n","            logits = model_cls(**batch)['logits']\n","\n","        # get probs\n","        probs = torch.nn.functional.softmax(\n","            logits, dim=1\n","        ).cpu().detach().numpy()\n","        all_probs.append(probs)\n","    \n","    return np.vstack(all_probs)"]},{"cell_type":"markdown","metadata":{},"source":["### lime importance "]},{"cell_type":"code","execution_count":308,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T23:50:15.163583Z","iopub.status.busy":"2023-12-11T23:50:15.162596Z","iopub.status.idle":"2023-12-11T23:50:15.175410Z","shell.execute_reply":"2023-12-11T23:50:15.174480Z","shell.execute_reply.started":"2023-12-11T23:50:15.163545Z"},"trusted":true},"outputs":[],"source":["def lime_importance(\n","    tokens: List[Tuple[str, int, int]], tokens_type: str, \n","    num_features:int=300, num_samples:int=700, device: str='cpu'\n",") -> List[str]:\n","\n","    assert tokens_type in ['razdel', 'natasha']\n","\n","    # список для наиболее важных слов\n","    essential_words = list()\n","    \n","    def RazdelSplit(text):\n","\n","        return [raz_tok.text for raz_tok in list(tokenize(text))]\n","\n","    def NatashaSplit(text):\n","\n","        segmenter = Segmenter()\n","        text_doc = Doc(text.lower())\n","        text_doc.segment(segmenter)\n","\n","        return [nat_tok['text'] for nat_tok in text_doc]\n","\n","    text_to_explain = gather_back_tokens(tokens, tokens_type)\n","\n","    if tokens_type == 'razdel':\n","        Spliter = RazdelSplit\n","    elif token_type == 'natasha':\n","        Spliter = NatashaSplit\n","    # создаем Explainer\n","    explainer = LimeTextExplainer(\n","        class_names=['Neg', 'Neu', 'Pos'],\n","        split_expression=Spliter\n","    )\n","\n","    # \"объясняем\" текст\n","    explanation = explainer.explain_instance(\n","        text_to_explain, partial(predict_texts,func_type='lime'), \n","        num_features=num_features, num_samples=num_samples\n","    )\n","\n","    # создаем mapping из токена в его вес LogReg\n","    explanation_list = explanation.as_list()\n","    tok2weight = {token:weight for token, weight in explanation_list}\n","\n","    # создаем список из токенов, их важности и позиции в тексте\n","    for token in tokens:\n","        if tokens_type == 'razdel':\n","            token_text = token.text.lower()\n","        else:\n","            token_text = token['text'].lower()\n","\n","        essential_words.append((\n","            token, tok2weight[token_text]\n","        ))\n","\n","    # создаем функцию сравнения важности\n","    sort_func = lambda x: np.abs(x[1])\n","    \n","    # сортируем токены по важности\n","    essential_words = sorted(essential_words, key=sort_func, reverse=True)\n","    print(essential_words)\n","\n","    # возвращаем только слова и их позиции в тексте\n","    essential_words = [word for word, _ in essential_words]\n","\n","    return essential_words"]},{"cell_type":"markdown","metadata":{},"source":["### shap importance"]},{"cell_type":"code","execution_count":309,"metadata":{"_cell_guid":"ff82fe94-6beb-4d7b-af9c-702319834adc","_uuid":"be5751b8-0b73-423e-9ae0-4a90461d1648","collapsed":false,"execution":{"iopub.execute_input":"2023-12-11T23:50:15.656255Z","iopub.status.busy":"2023-12-11T23:50:15.655865Z","iopub.status.idle":"2023-12-11T23:50:15.666862Z","shell.execute_reply":"2023-12-11T23:50:15.665650Z","shell.execute_reply.started":"2023-12-11T23:50:15.656207Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def shap_importance(\n","    tokens: List[str], tokens_type: str,\n","    target: int\n",") -> List[str]:\n","\n","    assert tokens_type in ['razdel', 'natasha']\n","\n","    # восстанавливаем текст из слов\n","    text_to_explain = gather_back_tokens(tokens,tokens_type)\n","\n","    def custom_tokenizer(\n","        text: str, return_offsets_mapping=True\n","    ) -> Dict[str, List[Union[str, Tuple[int, ...]]]]:\n","        \"\"\"Custom tokenizers conform to a subset of the transformers API.\"\"\"\n","        tokens = list(razdel.tokenize(text))\n","        \n","        words = list()\n","        offsets = list()\n","        for token in tokens:\n","            words.append(token.text)\n","            offsets.append((token.start, token.stop))\n","\n","        return {\n","            'input_ids': words,\n","            'offset_mapping': offsets\n","        }\n","\n","    masker = shap.maskers.Text(custom_tokenizer)\n","    explainer = shap.Explainer(\n","        partial(predict_texts,func_type='shap'), masker, \n","        output_names=['Neg', 'Neu', 'Pos']\n","    )\n","    # get shap values for the onliest text\n","    shap_values = explainer([text_to_explain])\n","\n","    tokens_order = shap_values.data[0]\n","    base_values = shap_values.base_values\n","    contributions = np.abs(shap_values.values[0]).sum(axis=1)\n","    essential_words = list(zip(tokens, contributions))\n","    \n","    sort_func = lambda x: x[1]\n","    \n","    essential_words = sorted(\n","        essential_words, key=sort_func, \n","        reverse=True\n","    )\n","    \n","    essential_words = [word for word, _ in essential_words]\n","    \n","    return essential_words"]},{"cell_type":"markdown","metadata":{},"source":["### alti importance"]},{"cell_type":"code","execution_count":310,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T23:50:15.983849Z","iopub.status.busy":"2023-12-11T23:50:15.983563Z","iopub.status.idle":"2023-12-11T23:50:15.998937Z","shell.execute_reply":"2023-12-11T23:50:15.998147Z","shell.execute_reply.started":"2023-12-11T23:50:15.983825Z"},"trusted":true},"outputs":[],"source":["model_cls_wrapper = ModelWrapper(model_cls)\n","\n","def alti_importance(\n","    tokens: List[Tuple[str, int, int]], tokens_type: str,\n","    measure_tokens_contributions: str\n",") -> List[str]:\n","\n","    assert measure_tokens_contributions in ['cls', 'all_tokens']\n","    assert tokens_type in ['razdel', 'natasha']\n","    \n","    text_to_explain = gather_back_tokens(tokens, tokens_type)\n","        \n","    text_tokens = tokenizer.tokenize(text_to_explain)\n","    text_input = tokenizer(\n","        text_to_explain, return_tensors=\"pt\", \n","        return_token_type_ids=False,\n","        return_offsets_mapping=True\n","    ).to(device)\n","    offset_mapping = text_input['offset_mapping'][0,1:-1,:].cpu().detach()\n","    text_input['return_dict'] = True\n","    del text_input['offset_mapping']\n","\n","    # get words of text\n","    words = list(razdel.tokenize(text_to_explain))\n","    pos_words = [(word.start, word.stop) for word in words]\n","\n","    # create mapping from token to word\n","    cur_index = 0\n","    token_pos_to_word = dict()\n","    for idx, (offset, token) in enumerate(zip(offset_mapping, text_tokens)):\n","        start, _ = offset\n","        while start >= pos_words[cur_index][1]:\n","            cur_index += 1\n","        token_pos_to_word[idx] = words[cur_index]\n","\n","    _, _, _, contributions_data = model_cls_wrapper(text_input)\n","\n","    # get Yi from alti\n","    resultant_norm = torch.norm(\n","        torch.squeeze(contributions_data['resultants']),\n","        p=1, dim=-1\n","    )\n","    # get Cij from alti method\n","    # 'contributions' means Tij\n","    # alti requires scaling = min_sum\n","    normalized_contributions = normalize_contributions(\n","        contributions_data['contributions'], scaling='min_sum',\n","        resultant_norm=resultant_norm\n","    )\n","\n","    # apply attention rollout and get seq of Ci\n","    contributions_mix = compute_joint_attention(normalized_contributions)\n","    # extract Ci after last self-attention layer\n","    joint_attention_layer = -1\n","    contributions_mix_last_hid = contributions_mix[joint_attention_layer]\n","\n","    if measure_tokens_contributions == 'cls':\n","        # contribution to token cls\n","        positions=np.array([0])\n","    else:\n","        positions=np.arange(len(contributions_mix_cls) - 2) + 1\n","\n","    word_to_contribution = defaultdict(float)\n","    for pos in positions:\n","        # get tokens contrubitons\n","        contributions_mix_cur = contributions_mix_last_hid[pos][1:-1]\n","        for idx, contribution in enumerate(contributions_mix_cur):\n","            word_to_contribution[token_pos_to_word[idx]] += contribution\n","    \n","    # функция для сортировки\n","    sort_func = lambda x: x[1]\n","    \n","    essential_words = sorted(\n","        [(word, cont) for word, cont in word_to_contribution.items()],\n","        key=sort_func, reverse=True\n","    )\n","    \n","    essential_words = [word for word, _ in essential_words]\n","    \n","    return essential_words"]},{"cell_type":"markdown","metadata":{},"source":["### Heuristic loss"]},{"cell_type":"code","execution_count":311,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T23:50:16.276335Z","iopub.status.busy":"2023-12-11T23:50:16.276000Z","iopub.status.idle":"2023-12-11T23:50:16.287839Z","shell.execute_reply":"2023-12-11T23:50:16.286925Z","shell.execute_reply.started":"2023-12-11T23:50:16.276308Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["def loss_importance(\n","    tokens: List[Tuple[str, int, int]], \n","    target: Union[int, str], tokens_type: str\n",") -> List[str]:\n","    \n","    assert tokens_type in ['razdel', 'natasha']\n","    \n","    text_to_explain = gather_back_tokens(tokens, tokens_type)\n","    \n","    # список для наиболее важных слов\n","    essential_words = list()\n","\n","    loss = torch.nn.CrossEntropyLoss()\n","    get_inputs = lambda x: tokenizer(\n","        x, padding=True,\n","        add_special_tokens=True,\n","        return_token_type_ids=False,\n","        return_tensors='pt'\n","    ).to(device)\n","\n","    # get inputs and outputs from model\n","    inputs = get_inputs(text_to_explain)\n","    inputs['return_dict'] = True\n","\n","    outputs = model_cls(**inputs)['logits']\n","    target_pt = torch.tensor([target], dtype=torch.long)\n","\n","    # calculate loss for original text\n","    loss_score_integral = loss(\n","        outputs.cpu(), target_pt\n","    )\n","\n","    for idx, token in enumerate(tokens):\n","        # get text without one token\n","        tokens_copy = tokens.copy()\n","        tokens_copy.pop(idx)\n","        text_to_explain = gather_back_tokens(tokens_copy, tokens_type)\n","\n","        # calculate loss without current word\n","        inputs = get_inputs(text_to_explain)\n","        inputs['return_dict'] = True\n","\n","        with torch.no_grad():\n","            outputs = model_cls(**inputs)['logits']\n","        loss_score_part = loss(outputs.cpu(), target_pt)\n","        # add our score of change\n","        essential_words.append((\n","            token, (loss_score_part-loss_score_integral).cpu().detach().numpy()\n","        ))\n","\n","    # создаем функцию сравнения важности\n","    sort_func = lambda x: x[1]\n","\n","    # сортируем токены по важности\n","    essential_words = sorted(essential_words, key=sort_func, reverse=True)\n","\n","    # возвращаем только слова и их позиции в тексте\n","    essential_words = [word for word, _ in essential_words]\n","\n","    return essential_words"]},{"cell_type":"markdown","metadata":{},"source":["### Random important words"]},{"cell_type":"code","execution_count":312,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T23:50:16.585414Z","iopub.status.busy":"2023-12-11T23:50:16.585029Z","iopub.status.idle":"2023-12-11T23:50:16.590805Z","shell.execute_reply":"2023-12-11T23:50:16.589804Z","shell.execute_reply.started":"2023-12-11T23:50:16.585385Z"},"trusted":true},"outputs":[],"source":["def extract_random_words(\n","    tokens: List[str]\n",") -> List[Tuple[str, int]]:\n","    \"\"\"\n","    возвращает список слов в случайном порядке\n","    \"\"\"\n","    permutation = np.random.permutation(len(tokens))\n","\n","    return [tokens[idx] for idx in permutation]"]},{"cell_type":"markdown","metadata":{"_cell_guid":"32811848-cf03-4d3e-a485-607a1e879aa1","_uuid":"ae956c6a-8df7-420b-8a63-ccaef04b1ac6","trusted":true},"source":["## char-level attacks"]},{"cell_type":"code","execution_count":313,"metadata":{"_cell_guid":"e083c436-9f81-4544-9205-387e75d2a8b1","_uuid":"d71ca614-f090-4867-9dd3-9a831b34223c","collapsed":false,"execution":{"iopub.execute_input":"2023-12-11T23:50:18.361876Z","iopub.status.busy":"2023-12-11T23:50:18.361498Z","iopub.status.idle":"2023-12-11T23:50:18.389956Z","shell.execute_reply":"2023-12-11T23:50:18.388878Z","shell.execute_reply.started":"2023-12-11T23:50:18.361845Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# функция для генерации состязательных примеров на уровне символов\n","def extract_spoiled_text_char_level(\n","        dataframe, words2spoil=2, \n","        sub_percent=0.15, sub_amount=1,\n","        mode2spoil='mixed', mode2amount='percent',\n","        importance='loss'\n","    ):\n","\n","\n","    def get_indexes2change(\n","        sub_letter: int, token_len: int\n","    ) -> List[int]:\n","        \"\"\"\n","        функция для получения индексов букв на замену (кроме 0)\n","        \"\"\"\n","        lst_to_random = list(range(1, token_len))\n","        np_ids = np.random.choice(lst_to_random, size=sub_letter, replace=False)\n","\n","        return np_ids.tolist()\n","    \n","    def make_token_change(\n","        indexes: List[int], token: str, mode='mixed'\n","    ):\n","        \"\"\"\n","        фукнция для замены букв по индексам с использованием 4 типов замены:\n","        del: только удаление\n","        ins: только вставка\n","        sub: только замена\n","        mixed: все вместе сразу\n","        \"\"\"\n","        if mode == 'sub':\n","            # заменяем букву на позиции\n","            word = list(token.text)\n","            for idx in indexes:\n","                symbol = word[idx]\n","                try:\n","                    word[idx] = key_errors[symbol][random.randint(0, len(key_errors[symbol])-1)]\n","                except:\n","                    pass\n","            return (token.start, token.stop, ''.join(word), 0)\n","        elif mode == 'ins':\n","            # вставляем букву на позиция и увеличиваем длину токена на 1\n","            ins_count = 0\n","            word = list(token.text)\n","            indexes = sorted(indexes)\n","            for idx in indexes:\n","                symbol = word[idx+ins_count]\n","                try:\n","                    word.insert(idx+ins_count, key_errors[symbol][random.randint(0, len(key_errors[symbol]) - 1)])\n","                    ins_count += 1\n","                except:\n","                    pass\n","            return (token.start, token.stop, ''.join(word), ins_count)\n","        elif mode == 'del':\n","            # удаляем букву на позиция и уменьшаем длину токена на 1\n","            del_count = 0\n","            word = list(token.text)\n","            indexes = sorted(indexes)\n","            for idx in indexes:\n","                if len(word) == 1:\n","                    break\n","                try:\n","                    word.pop(idx-del_count)\n","                    del_count += 1\n","                except:\n","                    pass\n","            return (token.start, token.stop, ''.join(word), -del_count)\n","        elif mode == 'mixed':\n","            ins_count = 0\n","            del_count = 0\n","            word = list(token.text)\n","            # генерируем самое первое действие в слове\n","            idx2action = random.randint(0, 2)\n","            indexes = sorted(indexes)\n","            for idx in indexes:\n","                # вставляем букву на позиция и увеличиваем длину токена на 1, если ins\n","                # удаляем букву на позиция и уменьшаем длину токена на 1, если del\n","                # заменяем букву на позиции, если sub\n","                new_idx = idx+ins_count-del_count\n","                try:\n","                    if idx2action == 0:\n","                        symbol = word[new_idx]\n","                        word[new_idx] = key_errors[symbol][random.randint(0, len(key_errors[symbol]) - 1)]\n","                        idx2action += 1\n","                    elif idx2action == 1:\n","                        word.insert(new_idx, key_errors[symbol][random.randint(0, len(key_errors[symbol]) - 1)])\n","                        ins_count += 1\n","                        idx2action += 1\n","                    elif idx2action == 2:\n","                        word.pop(new_idx)\n","                        del_count += 1\n","                        idx2action = 0 \n","                except:\n","                    pass\n","            return (token.start, token.stop, ''.join(word), ins_count-del_count)\n","\n","    # spoiled texts\n","    spoiled_text = list()\n","    pbar = tqdm(dataframe['text'], leave=True, position=0)\n","    for idx, sent, target1 in zip(\n","        range(len(dataframe['text'])), \n","        dataframe['text'], \n","        dataframe['0class']\n","    ):\n","        # get tokens of our text\n","        tokens = [data for data in list(tokenize(sent.lower()))]\n","        # just one word\n","        if len(tokens) == 1:\n","            spoiled_text.append(sent)\n","            continue\n","\n","        # выбираем определенным методом наиболее важные слова\n","        if importance == 'lime':\n","            word2spoil_order = lime_importance(\n","                tokens=tokens, tokens_type='razdel', \n","                device=device\n","            )\n","        elif importance == 'alti':\n","            word2spoil_order = alti_importance(\n","                tokens=tokens, tokens_type='razdel',\n","                measure_tokens_contributions='cls'\n","            )\n","        elif importance == 'shap':\n","            word2spoil_order = shap_importance(\n","                tokens=tokens, tokens_type='razdel',\n","                target=target1\n","            )\n","        elif importance == 'loss':\n","            word2spoil_order = loss_importance(\n","                tokens=tokens, tokens_type='razdel', \n","                target=target1\n","            )\n","        elif importance == 'random':\n","            word2spoil_order = extract_random_words(tokens)\n","\n","        sub_count = 0\n","        spoiled_tokens = list()\n","        for token in word2spoil_order:\n","            # get token and token's position\n","            token_len = token.stop - token.start\n","            # no way to change\n","            if token_len != 1 and sub_count < words2spoil: \n","                # count our changes\n","                if mode2amount == 'percent':\n","                    sub_letter = max(1, int(token_len * sub_percent))\n","                elif mode2amount == 'amount':\n","                    sub_letter = max(1, sub_amount)\n","                # get indexes to change\n","                indexes = get_indexes2change(sub_letter, token_len)\n","                # go through indexes\n","                spoiled_word = make_token_change(indexes, token, mode2spoil)\n","                # increase our subs\n","                sub_count += 1\n","                spoiled_tokens.append(spoiled_word)\n","            # сделали нужное количество порч\n","            if sub_count >= words2spoil:\n","                break\n","        \n","        # заменяем исходные слов в тексте испорченными\n","        shift_in_sent = 0\n","        spoiled_sent = list(sent.lower())\n","        spoiled_tokens = sorted(spoiled_tokens, key=lambda x:x[0])\n","        for spoiled in spoiled_tokens:\n","            spoiled_start, spoiled_stop, spoiled_word, word_shift = spoiled\n","            spoiled_sent[spoiled_start + shift_in_sent:spoiled_stop + shift_in_sent] = spoiled_word\n","            shift_in_sent += word_shift\n","        spoiled_sent = ''.join(spoiled_sent)\n","        spoiled_text.append(spoiled_sent)\n","        \n","        pbar.update(1)\n","        pbar.set_description(f'Total processed: {idx + 1}')\n","        \n","    return spoiled_text"]},{"cell_type":"markdown","metadata":{"_cell_guid":"8d5f880d-9df6-4595-96c2-5e31988b8d76","_uuid":"6ea8af42-a20a-45aa-8c3e-f7f9f58d8804","trusted":true},"source":["### Портим текст, вычисляем показатель use_score и accuracy"]},{"cell_type":"code","execution_count":267,"metadata":{"_cell_guid":"efa44e96-a095-433f-91c6-fe487359e517","_uuid":"1d64853f-94d1-4a6c-ac78-9bde88701737","collapsed":false,"execution":{"iopub.execute_input":"2023-12-11T23:42:14.034315Z","iopub.status.busy":"2023-12-11T23:42:14.033534Z","iopub.status.idle":"2023-12-11T23:42:14.048225Z","shell.execute_reply":"2023-12-11T23:42:14.047258Z","shell.execute_reply.started":"2023-12-11T23:42:14.034283Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def get_scores_char_spoiled_text(\n","        dataframe: pd.DataFrame, \n","        words2spoil: List[int], mode2amount: str,\n","        sub_amount: List[int], sub_percent: List[float],\n","        spoil_modes: List[str], importances: List[str]\n","    ) -> Tuple[Dict[str, float], Dict[str, float], Dict[str, float], pd.DataFrame]:\n","    \"\"\"\n","    dataframe: (pandas данные с текстом и метками)\n","    mode2amount: 'percent', 'amount' (по процентам или по количеству букв)\n","    words2spoil_amount: (количество слов для порчи)\n","    subs: (сколько букв испортить)\n","    subs_percent: (сколько букв в процентах от слова испортить)\n","    spoil_modes: 'mixed', 'ins', 'del', 'sub' (способы порчи текста)\n","    spoil_init: 'random', 'loss', 'lime' (тип выбора слов для порчи)\n","    \"\"\"\n","    \n","    assert mode2amount in ['percent', 'amount']\n","    assert set(importances) <= {'loss', 'shap', 'lime', 'random', 'alti'}\n","    assert set(spoil_modes) <= {'mixed', 'ins', 'del', 'sub'}\n","    assert all(amount > 0 for amount in words2spoil)\n","    assert all(sub >= 1 for sub in sub_amount)\n","    assert all(sub >= 0.05 for sub in sub_percent)\n","    \n","    dan_scores = dict()\n","    bert_scores = dict()\n","    acc_scores = dict()\n","    \n","    subs = sub_percent if mode2amount == 'percent' else sub_amount\n","\n","    for importance in importances:\n","        for sub in subs:\n","            for mode2spoil in spoil_modes:\n","                for words_amount in words2spoil:\n","\n","                    col_name = f'{importance}_{words_amount}_{mode2spoil}_{mode2amount}_{sub}_CharSpoiledText'\n","                    # генерируем состязательные примеры\n","                    spoiled_text = extract_spoiled_text_char_level(\n","                        dataframe, words2spoil=words_amount,\n","                        sub_amount=sub, sub_percent=sub, mode2amount=mode2amount, \n","                        mode2spoil=mode2spoil, importance=importance\n","                    )\n","                    \n","                    # сохраняем колонку со состязательными примерами\n","                    dataframe[col_name] = spoiled_text\n","                    \n","                    # считаем use score на основе представлений bert\n","                    _, use_result_char_bert = use_score(\n","                        dataframe['text'],\n","                        dataframe[col_name],\n","                        use_bert_encoder=True,\n","                        model=model\n","                    )\n","                    # считаем use score на основе dan кодировщика\n","                    _, use_result_char = use_score(\n","                        dataframe['text'],\n","                        dataframe[col_name]\n","                    )\n","\n","                    sentidata = SentimentDataTransformer(\n","                        texts=..., labels=...\n","                    )\n","                    \n","                    loader_sentidata = DataLoader(\n","                        sentidata, batch_size=16, shuffle=False,\n","                        collate_fn=collate_fn_transformers(\n","                            tokenizer=tokenizer, use_tok_type_ids=False, max_len=seq_mas_len\n","                        )\n","                    )\n","\n","                    # замеряем качество состязательных примеров\n","                    spoiled_accuracy_char = calculate_accuracy(model, loader_sentidata, device)\n","                    \n","                    # сохраняем результаты\n","                    dan_scores[col_name] = use_result_char\n","                    bert_scores[col_name] = use_result_char_bert\n","                    acc_scores[col_name] = spoiled_accuracy_char\n","                \n","    return dan_scores, bert_scores, acc_scores, dataframe"]},{"cell_type":"code","execution_count":325,"metadata":{"_cell_guid":"99b6d519-3d2f-4d94-919a-15807f99a32d","_uuid":"ad6d6ffe-47cf-46ae-958d-effdfa8438ee","collapsed":false,"execution":{"iopub.execute_input":"2023-12-11T23:52:41.771286Z","iopub.status.busy":"2023-12-11T23:52:41.770880Z","iopub.status.idle":"2023-12-11T23:52:45.764161Z","shell.execute_reply":"2023-12-11T23:52:45.762955Z","shell.execute_reply.started":"2023-12-11T23:52:41.771254Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Total processed: 1:   0%|          | 1/2120 [00:00<10:32,  3.35it/s]"]},{"name":"stdout","output_type":"stream","text":["[(Substring(59, 65, 'русала'), 0.17499618625666669), (Substring(35, 52, 'реструктурировать'), 0.1473447059169203), (Substring(21, 34, 'необходимости'), 0.1217962788837209), (Substring(15, 20, 'нашли'), -0.11842125627977523), (Substring(12, 14, 'не'), -0.07403943424715557), (Substring(2, 11, 'сбербанке'), -0.06740369093477944), (Substring(58, 59, '\"'), 0.05371174669144409), (Substring(65, 66, '\"'), 0.05371174669144409), (Substring(53, 57, 'долг'), -0.0401951530899513), (Substring(0, 1, 'в'), -0.02678929812681088)]\n"]},{"name":"stderr","output_type":"stream","text":["Total processed: 2:   0%|          | 2/2120 [00:00<09:12,  3.83it/s]"]},{"name":"stdout","output_type":"stream","text":["[(Substring(7, 11, 'дали'), -0.5541643074842184), (Substring(4, 6, 'не'), -0.41613853543188084), (Substring(19, 20, 'в'), 0.11181120371189801), (Substring(21, 30, 'сбербанке'), -0.0966923379447318), (Substring(12, 18, 'кредит'), 0.06361010985638435), (Substring(0, 2, 'rt'), -0.021856783650271657)]\n"]},{"name":"stderr","output_type":"stream","text":["Total processed: 3:   0%|          | 3/2120 [00:00<09:43,  3.63it/s]"]},{"name":"stdout","output_type":"stream","text":["[(Substring(37, 38, '»'), 0.17124000619788585), (Substring(0, 12, 'рекомендации'), -0.07171309152996208), (Substring(25, 33, 'сбербанк'), -0.06905196645147835), (Substring(13, 15, 'по'), -0.057367067840748534), (Substring(39, 49, 'переоценил'), -0.052652366925402795), (Substring(22, 23, ':'), -0.03992488364409207), (Substring(24, 25, '«'), 0.022119279488510103), (Substring(50, 63, 'медиакомпании'), 0.009829513046289406), (Substring(34, 37, 'cib'), -0.0060725623278805), (Substring(16, 22, 'акциям'), 0.005370893042210175)]\n"]},{"name":"stderr","output_type":"stream","text":["Total processed: 4:   0%|          | 4/2120 [00:01<12:04,  2.92it/s]"]},{"name":"stdout","output_type":"stream","text":["[(Substring(55, 59, 'было'), -0.06025674972661085), (Substring(106, 110, 'андр'), 0.05582484274403715), (Substring(95, 104, 'сбербанка'), 0.04734432906382417), (Substring(28, 39, 'приватбанка'), 0.043108108201767796), (Substring(77, 93, 'государственного'), 0.04097168772994914), (Substring(52, 54, 'не'), -0.04096473788771755), (Substring(59, 60, ','), -0.03512733882626919), (Substring(61, 62, '—'), -0.031504476561571106), (Substring(104, 105, '»'), 0.022465039064638544), (Substring(63, 69, 'пышный'), -0.01857470473305516), (Substring(110, 113, '...'), -0.015554345436045868), (Substring(71, 76, 'глава'), 0.014535830059086971), (Substring(0, 11, 'переговоров'), -0.012273706448780054), (Substring(69, 70, ':'), 0.011315711629357805), (Substring(42, 51, 'сбербанку'), -0.007818251289837132), (Substring(12, 13, 'о'), -0.007667650240984489), (Substring(14, 27, 'присоединении'), 0.006614244470092058), (Substring(94, 95, '«'), -0.005954351758178778), (Substring(40, 41, 'к'), -0.004727156836019839)]\n"]},{"name":"stderr","output_type":"stream","text":["Total processed: 5:   0%|          | 5/2120 [00:01<12:07,  2.91it/s]"]},{"name":"stdout","output_type":"stream","text":["[(Substring(47, 56, 'сбербанке'), 0.4268225685231348), (Substring(19, 28, 'четвертую'), -0.15991438034827762), (Substring(4, 9, 'можно'), -0.1494012269845187), (Substring(29, 34, 'карту'), 0.14772617215077646), (Substring(63, 64, '.'), -0.1413518079539435), (Substring(10, 18, 'потерять'), -0.12779336371390632), (Substring(45, 46, 'в'), 0.07618708441308057), (Substring(41, 44, 'уже'), -0.06538750659622858), (Substring(57, 63, 'узнают'), 0.05565195855966747), (Substring(0, 3, 'как'), -0.0438922769440838), (Substring(34, 36, '?!'), -0.024974218154429153), (Substring(36, 40, 'меня'), -0.019997137742118937)]\n"]},{"name":"stderr","output_type":"stream","text":["Total processed: 6:   0%|          | 6/2120 [00:01<11:02,  3.19it/s]"]},{"name":"stdout","output_type":"stream","text":["[(Substring(9, 16, 'понизил'), -0.6411809229960604), (Substring(17, 23, 'ставки'), -0.3630537931705997), (Substring(36, 43, 'вкладам'), -0.14739360726502865), (Substring(0, 8, 'сбербанк'), -0.13543994507918253), (Substring(27, 35, 'рублевым'), -0.09694433987076884), (Substring(24, 26, 'по'), 0.007695040640761638)]\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>importances = [<span style=\"color: #808000; text-decoration-color: #808000\">'lime'</span>]                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>words2spoil_amount = [<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>]                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 7 dan_scores_char, bert_scores_char, acc_scores_char, adversial_examples_char = get_scores    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>adversial_examples_char,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>words2spoil=words2spoil_amount,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>mode2amount=mode2amount,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_scores_char_spoiled_text</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">37</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>col_name = <span style=\"color: #808000; text-decoration-color: #808000\">f'{</span>importance<span style=\"color: #808000; text-decoration-color: #808000\">}_{</span>words_amount<span style=\"color: #808000; text-decoration-color: #808000\">}_{</span>mode2spoil<span style=\"color: #808000; text-decoration-color: #808000\">}_{</span>mode2amount<span style=\"color: #808000; text-decoration-color: #808000\">}_</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># генерируем состязательные примеры</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>37 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>spoiled_text = extract_spoiled_text_char_level(                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>dataframe, words2spoil=words_amount,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">39 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>sub_amount=sub, sub_percent=sub, mode2amount=mode2amount,           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">40 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>mode2spoil=mode2spoil, importance=importance                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">extract_spoiled_text_char_level</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">114</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># выбираем определенным методом наиболее важные слова</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> importance == <span style=\"color: #808000; text-decoration-color: #808000\">'lime'</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>114 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>word2spoil_order = lime_importance(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>tokens=tokens, tokens_type=<span style=\"color: #808000; text-decoration-color: #808000\">'razdel'</span>,                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>device=device                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">lime_importance</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">36</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>)                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># \"объясняем\" текст</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>36 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>explanation = explainer.explain_instance(                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>text_to_explain, partial(predict_texts,func_type=<span style=\"color: #808000; text-decoration-color: #808000\">'lime'</span>),                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>num_features=num_features, num_samples=num_samples                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">39 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>)                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/lime/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">lime_text.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">413</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">explain_instance</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">410 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   </span>split_expression=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.split_expression,            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">411 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   </span>mask_string=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mask_string))                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">412 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>domain_mapper = TextDomainMapper(indexed_string)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>413 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>data, yss, distances = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.__data_labels_distances(                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">414 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>indexed_string, classifier_fn, num_samples,                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">415 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>distance_metric=distance_metric)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">416 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.class_names <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/lime/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">lime_text.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">482</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__data_labels_distances</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">479 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │   │   </span>replace=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">480 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data[i, inactive] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>inverse_data.append(indexed_string.inverse_removing(inactive))                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>482 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>labels = classifier_fn(inverse_data)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">483 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>distances = distance_fn(sp.sparse.csr_matrix(data))                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">484 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data, labels, distances                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">485 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict_texts</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">27</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>batch[<span style=\"color: #808000; text-decoration-color: #808000\">'return_dict'</span>] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>27 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>logits = model_cls(**batch)[<span style=\"color: #808000; text-decoration-color: #808000\">'logits'</span>]                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># get probs</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>probs = torch.nn.functional.softmax(                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_distilbert.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">76</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 760 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 761 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>return_dict = return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.use_return  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 762 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 763 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>distilbert_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.distilbert(                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 764 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>input_ids=input_ids,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 765 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attention_mask=attention_mask,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 766 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>head_mask=head_mask,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_distilbert.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">58</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 580 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 581 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>embeddings = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embeddings(input_ids, inputs_embeds)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># (bs, seq_length, dim)</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 582 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 583 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transformer(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 584 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>x=embeddings,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 585 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attn_mask=attention_mask,                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 586 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>head_mask=head_mask,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_distilbert.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">35</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">9</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 356 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> output_hidden_states:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 357 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>all_hidden_states = all_hidden_states + (hidden_state,)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 358 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 359 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>layer_outputs = layer_module(                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 360 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>x=hidden_state, attn_mask=attn_mask, head_mask=head_mask[i], output_atte  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 361 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 362 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>hidden_state = layer_outputs[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_distilbert.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">31</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 310 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>sa_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sa_layer_norm(sa_output + x)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># (bs, seq_length, dim)</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 311 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 312 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Feed Forward Network</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 313 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>ffn_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ffn(sa_output)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># (bs, seq_length, dim)</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 314 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>ffn_output: torch.Tensor = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.output_layer_norm(ffn_output + sa_output)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># (bs</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 315 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 316 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output = (ffn_output,)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_distilbert.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">25</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 251 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.activation = get_activation(config.activation)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 252 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 253 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: torch.Tensor) -&gt; torch.Tensor:                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 254 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> apply_chunking_to_forward(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ff_chunk, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.chunk_size_feed_forward, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">se</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 255 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ff_chunk</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: torch.Tensor) -&gt; torch.Tensor:                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 257 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lin1(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pytorch_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">237</span> in                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">apply_chunking_to_forward</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">234 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># concatenate output at same dimension</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">235 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch.cat(output_chunks, dim=chunk_dim)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">236 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>237 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_fn(*input_tensors)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">239 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">240 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">find_pruneable_heads_and_indices</span>(                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_distilbert.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">25</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ff_chunk</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 254 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> apply_chunking_to_forward(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ff_chunk, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.chunk_size_feed_forward, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">se</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 255 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ff_chunk</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: torch.Tensor) -&gt; torch.Tensor:                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 257 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lin1(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 258 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.activation(x)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 259 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lin2(x)                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 260 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dropout(x)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">linear.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">114</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>init.uniform_(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias, -bound, bound)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>114 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.linear(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">extra_repr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #808000; text-decoration-color: #808000\">'in_features={}, out_features={}, bias={}'</span>.format(                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n","</pre>\n"],"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m7\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0mimportances = [\u001b[33m'\u001b[0m\u001b[33mlime\u001b[0m\u001b[33m'\u001b[0m]                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0mwords2spoil_amount = [\u001b[94m1\u001b[0m, \u001b[94m2\u001b[0m]                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 7 dan_scores_char, bert_scores_char, acc_scores_char, adversial_examples_char = get_scores    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   \u001b[0madversial_examples_char,                                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   \u001b[0mwords2spoil=words2spoil_amount,                                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   \u001b[0mmode2amount=mode2amount,                                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mget_scores_char_spoiled_text\u001b[0m:\u001b[94m37\u001b[0m                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m34 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m                                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcol_name = \u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mimportance\u001b[33m}\u001b[0m\u001b[33m_\u001b[0m\u001b[33m{\u001b[0mwords_amount\u001b[33m}\u001b[0m\u001b[33m_\u001b[0m\u001b[33m{\u001b[0mmode2spoil\u001b[33m}\u001b[0m\u001b[33m_\u001b[0m\u001b[33m{\u001b[0mmode2amount\u001b[33m}\u001b[0m\u001b[33m_\u001b[0m    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# генерируем состязательные примеры\u001b[0m                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m37 \u001b[2m│   │   │   │   │   \u001b[0mspoiled_text = extract_spoiled_text_char_level(                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m38 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mdataframe, words2spoil=words_amount,                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m39 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0msub_amount=sub, sub_percent=sub, mode2amount=mode2amount,           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m40 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mmode2spoil=mode2spoil, importance=importance                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mextract_spoiled_text_char_level\u001b[0m:\u001b[94m114\u001b[0m                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# выбираем определенным методом наиболее важные слова\u001b[0m                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m importance == \u001b[33m'\u001b[0m\u001b[33mlime\u001b[0m\u001b[33m'\u001b[0m:                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   │   \u001b[0mword2spoil_order = lime_importance(                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtokens=tokens, tokens_type=\u001b[33m'\u001b[0m\u001b[33mrazdel\u001b[0m\u001b[33m'\u001b[0m,                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdevice=device                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mlime_importance\u001b[0m:\u001b[94m36\u001b[0m                                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m33 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m34 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# \"объясняем\" текст\u001b[0m                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m36 \u001b[2m│   \u001b[0mexplanation = explainer.explain_instance(                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m37 \u001b[0m\u001b[2m│   │   \u001b[0mtext_to_explain, partial(predict_texts,func_type=\u001b[33m'\u001b[0m\u001b[33mlime\u001b[0m\u001b[33m'\u001b[0m),                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m38 \u001b[0m\u001b[2m│   │   \u001b[0mnum_features=num_features, num_samples=num_samples                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m39 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/lime/\u001b[0m\u001b[1;33mlime_text.py\u001b[0m:\u001b[94m413\u001b[0m in \u001b[92mexplain_instance\u001b[0m                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m410 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   \u001b[0msplit_expression=\u001b[96mself\u001b[0m.split_expression,            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m411 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   \u001b[0mmask_string=\u001b[96mself\u001b[0m.mask_string))                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m412 \u001b[0m\u001b[2m│   │   \u001b[0mdomain_mapper = TextDomainMapper(indexed_string)                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m413 \u001b[2m│   │   \u001b[0mdata, yss, distances = \u001b[96mself\u001b[0m.__data_labels_distances(                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m414 \u001b[0m\u001b[2m│   │   │   \u001b[0mindexed_string, classifier_fn, num_samples,                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m415 \u001b[0m\u001b[2m│   │   │   \u001b[0mdistance_metric=distance_metric)                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m416 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.class_names \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/lime/\u001b[0m\u001b[1;33mlime_text.py\u001b[0m:\u001b[94m482\u001b[0m in \u001b[92m__data_labels_distances\u001b[0m         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m479 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   \u001b[0mreplace=\u001b[94mFalse\u001b[0m)                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m480 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata[i, inactive] = \u001b[94m0\u001b[0m                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m481 \u001b[0m\u001b[2m│   │   │   \u001b[0minverse_data.append(indexed_string.inverse_removing(inactive))                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m482 \u001b[2m│   │   \u001b[0mlabels = classifier_fn(inverse_data)                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m483 \u001b[0m\u001b[2m│   │   \u001b[0mdistances = distance_fn(sp.sparse.csr_matrix(data))                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m484 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m data, labels, distances                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m485 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mpredict_texts\u001b[0m:\u001b[94m27\u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m24 \u001b[0m\u001b[2m│   │   \u001b[0mbatch[\u001b[33m'\u001b[0m\u001b[33mreturn_dict\u001b[0m\u001b[33m'\u001b[0m] = \u001b[94mTrue\u001b[0m                                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m25 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m27 \u001b[2m│   │   │   \u001b[0mlogits = model_cls(**batch)[\u001b[33m'\u001b[0m\u001b[33mlogits\u001b[0m\u001b[33m'\u001b[0m]                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m28 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m29 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# get probs\u001b[0m                                                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m30 \u001b[0m\u001b[2m│   │   \u001b[0mprobs = torch.nn.functional.softmax(                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/\u001b[0m\u001b[1;33mmodeling_distilbert.py\u001b[0m:\u001b[94m76\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[94m3\u001b[0m in \u001b[92mforward\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 760 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 761 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.config.use_return  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 762 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 763 \u001b[2m│   │   \u001b[0mdistilbert_output = \u001b[96mself\u001b[0m.distilbert(                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 764 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids=input_ids,                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 765 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 766 \u001b[0m\u001b[2m│   │   │   \u001b[0mhead_mask=head_mask,                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/\u001b[0m\u001b[1;33mmodeling_distilbert.py\u001b[0m:\u001b[94m58\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[94m3\u001b[0m in \u001b[92mforward\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 580 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 581 \u001b[0m\u001b[2m│   │   \u001b[0membeddings = \u001b[96mself\u001b[0m.embeddings(input_ids, inputs_embeds)  \u001b[2m# (bs, seq_length, dim)\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 582 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 583 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.transformer(                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 584 \u001b[0m\u001b[2m│   │   │   \u001b[0mx=embeddings,                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 585 \u001b[0m\u001b[2m│   │   │   \u001b[0mattn_mask=attention_mask,                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 586 \u001b[0m\u001b[2m│   │   │   \u001b[0mhead_mask=head_mask,                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/\u001b[0m\u001b[1;33mmodeling_distilbert.py\u001b[0m:\u001b[94m35\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[94m9\u001b[0m in \u001b[92mforward\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 356 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m output_hidden_states:                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 357 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mall_hidden_states = all_hidden_states + (hidden_state,)                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 358 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 359 \u001b[2m│   │   │   \u001b[0mlayer_outputs = layer_module(                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 360 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mx=hidden_state, attn_mask=attn_mask, head_mask=head_mask[i], output_atte  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 361 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 362 \u001b[0m\u001b[2m│   │   │   \u001b[0mhidden_state = layer_outputs[-\u001b[94m1\u001b[0m]                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/\u001b[0m\u001b[1;33mmodeling_distilbert.py\u001b[0m:\u001b[94m31\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[94m3\u001b[0m in \u001b[92mforward\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 310 \u001b[0m\u001b[2m│   │   \u001b[0msa_output = \u001b[96mself\u001b[0m.sa_layer_norm(sa_output + x)  \u001b[2m# (bs, seq_length, dim)\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 311 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 312 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Feed Forward Network\u001b[0m                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 313 \u001b[2m│   │   \u001b[0mffn_output = \u001b[96mself\u001b[0m.ffn(sa_output)  \u001b[2m# (bs, seq_length, dim)\u001b[0m                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 314 \u001b[0m\u001b[2m│   │   \u001b[0mffn_output: torch.Tensor = \u001b[96mself\u001b[0m.output_layer_norm(ffn_output + sa_output)  \u001b[2m# (bs\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 315 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 316 \u001b[0m\u001b[2m│   │   \u001b[0moutput = (ffn_output,)                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/\u001b[0m\u001b[1;33mmodeling_distilbert.py\u001b[0m:\u001b[94m25\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[94m4\u001b[0m in \u001b[92mforward\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 251 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.activation = get_activation(config.activation)                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 252 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 253 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: torch.Tensor) -> torch.Tensor:                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 254 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m apply_chunking_to_forward(\u001b[96mself\u001b[0m.ff_chunk, \u001b[96mself\u001b[0m.chunk_size_feed_forward, \u001b[96mse\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 255 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 256 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mff_chunk\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: torch.Tensor) -> torch.Tensor:                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 257 \u001b[0m\u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.lin1(\u001b[96minput\u001b[0m)                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mpytorch_utils.py\u001b[0m:\u001b[94m237\u001b[0m in                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[92mapply_chunking_to_forward\u001b[0m                                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m234 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# concatenate output at same dimension\u001b[0m                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m235 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m torch.cat(output_chunks, dim=chunk_dim)                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m236 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m237 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m forward_fn(*input_tensors)                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m238 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m239 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m240 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mfind_pruneable_heads_and_indices\u001b[0m(                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/\u001b[0m\u001b[1;33mmodeling_distilbert.py\u001b[0m:\u001b[94m25\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[94m7\u001b[0m in \u001b[92mff_chunk\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 254 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m apply_chunking_to_forward(\u001b[96mself\u001b[0m.ff_chunk, \u001b[96mself\u001b[0m.chunk_size_feed_forward, \u001b[96mse\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 255 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 256 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mff_chunk\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: torch.Tensor) -> torch.Tensor:                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 257 \u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.lin1(\u001b[96minput\u001b[0m)                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 258 \u001b[0m\u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.activation(x)                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 259 \u001b[0m\u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.lin2(x)                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 260 \u001b[0m\u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.dropout(x)                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mlinear.py\u001b[0m:\u001b[94m114\u001b[0m in \u001b[92mforward\u001b[0m                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0minit.uniform_(\u001b[96mself\u001b[0m.bias, -bound, bound)                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.linear(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.bias)                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mextra_repr\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[96mstr\u001b[0m:                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[33m'\u001b[0m\u001b[33min_features=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m, out_features=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m, bias=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m'\u001b[0m.format(                          \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mKeyboardInterrupt\u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["mode2amount = 'amount'\n","sub_amount, sub_percent = [1], [0.05]\n","spoil_modes = ['ins', 'del', 'sub']\n","importances = ['lime']\n","words2spoil_amount = [1, 2]\n","\n","dan_scores_char, bert_scores_char, acc_scores_char, adversial_examples_char = get_scores_char_spoiled_text(\n","    adversial_examples_char,\n","    words2spoil=words2spoil_amount,\n","    mode2amount=mode2amount,\n","    sub_amount=sub_amount, sub_percent=sub_percent,\n","    spoil_modes=spoil_modes, importances=importances\n",")"]},{"cell_type":"markdown","metadata":{"_cell_guid":"c6b59874-65d5-467a-af95-3163f18e52c9","_uuid":"416b233b-03d4-482f-999b-0f486ac4df96","trusted":true},"source":["### Сохраняем все результаты"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5e6d79b8-7e9f-4ac7-95c4-23939007d726","_uuid":"329e80fe-92d5-44ba-8ede-646087b2dbe5","collapsed":false,"execution":{"iopub.execute_input":"2023-12-05T00:03:25.641255Z","iopub.status.busy":"2023-12-05T00:03:25.640654Z","iopub.status.idle":"2023-12-05T00:03:25.670652Z","shell.execute_reply":"2023-12-05T00:03:25.669927Z","shell.execute_reply.started":"2023-12-05T00:03:25.641220Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# сохраняем состязательные примеры\n","adversial_examples_char.to_csv('adversial_examples_char.csv')\n","\n","# создание pd.DataFrame с бъединенными данными\n","scores = [dan_scores_char, bert_scores_char, acc_scores_char]\n","names = ['dan_score', 'bert_score', 'acc_score']\n","dataframes = list()\n","\n","# создаем список отдельных dataframe\n","for name, score in zip(names, scores):\n","    score_dct = {\n","        'modification': list(),\n","        name: list()\n","    }\n","    for key, val in score.items():\n","        score_dct['modification'].append(key)\n","        score_dct[name].append(val)\n","    dataframes.append(pd.DataFrame(score_dct))\n","\n","# merge всех dataframe\n","init_dataframe = dataframes[0]\n","for i in range(1, len(dataframes)):\n","    init_dataframe = init_dataframe.merge(dataframes[i], how='left', on='modification')\n","\n","init_dataframe['importance'] = init_dataframe['modification'].apply(lambda x: x.split('_')[0])\n","init_dataframe['modification'] = init_dataframe['modification'].apply(lambda x: '_'.join(x.split('_')[1:]))\n","\n","# init_dataframe = init_dataframe.set_index('modification')"]},{"cell_type":"markdown","metadata":{"_cell_guid":"17e1e040-5c3a-4c1b-ab06-d5c0de7dd007","_uuid":"005cac6e-0f3b-4114-9b53-9648f2328ab3","trusted":true},"source":["### Графики зависимостей символов"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f5e88d2f-b7ad-41c7-92ad-317ce989ff3d","_uuid":"6eb78e58-b305-48cd-af80-f373d8bb74bf","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["orig_acc = 0.762\n","orig_dan = 1\n","orig_use = 1\n","\n","def plot_char_results(method: str, modification2value: Dict[str, float]) -> None:\n","    \n","    # сохраняем mappings от (способ порчи, кол-во испорченных слов)\n","    # к полученному результату\n","    bert_method_to_res = dict()\n","    acc_method_to_res = dict()\n","    dan_method_to_res = dict()\n","    # есть ли в результатах данный метод оценки важности слова\n","    used_method = False\n","    # получаем имена всех модификаций\n","    modifications = modification2value.keys()\n","    for modification in modifications:\n","        modification_parts = modification.split('_')\n","        # получаем характеристики модификации\n","        importance = modification_parts[0]\n","        spoil_method = modification_parts[2]\n","        words_amount = modification_parts[1]\n","        sub = modification_parts[4]\n","        # если хотим визуализировать другой метод\n","        if importance != method:\n","            continue\n","        used_method = True\n","        # получаем и сохраняем результаты\n","        bert_score = bert_scores_char[modification]\n","        dan_score = dan_scores_char[modification]\n","        acc_score = acc_scores_char[modification]\n","        \n","        if bert_method_to_res.get((spoil_method, words_amount), None) is None:\n","            bert_method_to_res[(spoil_method, words_amount)] = [(orig_acc, 0)]\n","        if dan_method_to_res.get((spoil_method, words_amount), None) is None:\n","            dan_method_to_res[(spoil_method, words_amount)] = [(orig_dan, 0)]\n","        if acc_method_to_res.get((spoil_method, words_amount), None) is None:\n","            acc_method_to_res[(spoil_method, words_amount)] = [(orig_use, 0)]\n","\n","        bert_method_to_res[(spoil_method, words_amount)].append((bert_score, sub))\n","        acc_method_to_res[(spoil_method, words_amount)].append((acc_score, sub))\n","        dan_method_to_res[(spoil_method, words_amount)].append((dan_score, sub))\n","    \n","    assert used_method\n","    \n","    names = ['accuracy', 'dan_sim', 'bert_sim']\n","    scores = [acc_method_to_res, dan_method_to_res, bert_method_to_res]\n","    _, axes = plt.subplots(3, 1, figsize=(20, 10))\n","    \n","    for idx, (name, mapping) in enumerate(zip(names, scores)):\n","        subs = None\n","        for key, value in mapping.items():\n","            if subs is None:\n","                subs = [sub for _, sub in value]\n","            results = [result for result, _ in value]\n","\n","            axes[idx].plot(results, label=''.join(key))\n","        \n","        axes[idx].set_xlable('spoil chars amount')\n","        axes[idx].set_ylabel(name)\n","        axes[idx].set_title(f'{name} with {method} depending on spoil chars amount')\n","        axes[idx].set_xticklabel(subs)\n","        axes[idx].legend()\n","        axes[idx].grid(True)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3505809,"sourceId":6116952,"sourceType":"datasetVersion"},{"datasetId":3511519,"sourceId":6125391,"sourceType":"datasetVersion"},{"datasetId":4135938,"sourceId":7160860,"sourceType":"datasetVersion"},{"datasetId":4148625,"sourceId":7178339,"sourceType":"datasetVersion"}],"dockerImageVersionId":30528,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
