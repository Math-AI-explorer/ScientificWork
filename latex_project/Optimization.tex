ну\section{Постановка экспериментов}
\label{sec:Optimization} \index{Optimization}

\noindent\hspace{0.6cm} В качестве методов для составления состязательных примеров  использовались следующие операции:
\begin{enumerate}
    \item Символьные опечатки наиболее важных слов заменой, вставкой или замещением соседних на клавиатуре символов;
    \item Замены наиболее важных слов синонимами с дальнейшим встраиванием (прогнозирование морфологических признаков) их в контекст предложения. Итоговое слово конструируется с помощью предобученного MLM BERT, который предсказывает морфологическое окончание для лемматизированного подобранного синонима \ref{sec:AdvWord}. Синоним для исходного лемматизированного слова искался путем минимизации косинусного расстояния;
\end{enumerate} Так как на поставленную задачу были поставлены ограничения в виде близкого \textbf{семантического} или \textbf{визуального} сходства, то для генерации состязательных примеров допускается 1 символьное искажение (удаление, замена или вставка соседнего на клавиатуре символа) 1 или 2 слов в тексте, либо замена 1 или 2 слов синонимами.

\noindent\hspace{0.6cm}Однако сначала во всех методах порождения состязательных примеров надо определить последовательность слов, подлежащих изменению, путем вычисления их важности. Сделать это можно двумя способами:

\begin{itemize}
    \item Рассматривается предложение $S = \{w_1, w_2, ..., w_n\}$, где $w_i$ представляет собой токен текста. После удаления слова $w_i$ результирующий пример обозначается $S\backslash w_i = S\backslash\{w_i\} = \{w_1, ..., w_{i-1}, w_{i+1}, ..., w_n\}$. Модель, подлежащая атаке, $M_y(\text{-})$, используется для представления оценки прогнозирования для метки $y$. Оценка важности $I_{w_i}$ рассчитывается как разница между оценкой предсказания до и после удаления слова $w_i$ из предложения, которая формально определяется следующим образом:
    \begin{equation*}
        I_{w_i} = My(S) - My(S\backslash w_i)
    \end{equation*}
    Таким образом, получены оценки важности для каждого слова в предложении. Затем они используются для выбора наиболее влиятельных слов в контексте атакуемой модели. К данной группе можно отнести, например, метод \textbf{SHAP}.
    \item Извлечение важности каждого отдельного токена текста за счет интерпретации прогноза модели на входных данных. К данной группе можно отнести такие методы как: \textbf{Attention}, \textbf{ALTI}, \textbf{LIME}, \textbf{Gradient}.
\end{itemize}
Основной интерес вызывает вопрос: какой из методов извлечения важности токенов при заданных ограничениях на задачу приведет к лучшему качеству сгенерированных состязательных примеров.

\subsection{baseline решение}

\noindent\hspace{0.6cm}В качестве baseline решения рассматриваются следующие методы выделения наиболее важных слов для прогноза: \textbf{loss} и \textbf{random}.

\subsubsection{Loss}

\hspace{0.6cm}Данный способ выделения важности токенов относится к первой группе, то есть пусть $F(x)$ - некоторая целевая оценочная функция, которая принимает на вход метку класса для текста и сам текст и затем в качестве результата выдает скалярное значение. Чем выше/ниже значение этого результата, тем менее подходящим оказался текст для данной метки. Таким образом, выкидывая различные слова из текста, можно оценивать их важность для предсказания модели. В задаче классификации в качестве функции $F$ можно взять \textbf{CrossEntropyLoss}. Плюсом данного подхода также является то, что эксплуатация исходной модели происходит в режиме "чёрного ящика" и не зависит от ее внутреннего устройства. С другой стороны, в отличии от других рассматриваемых методов Loss работает только с размеченными объектами из выборки.

\subsubsection{Random}

\noindent\hspace{0.6cm}Название метода говорит само за себя, вместо целенаправленной оценки важности слов для предсказания модели используется \textbf{стохастическое сэмплирование} порядка слов из некоторого распределения. Данный метод может сэмплировать как хорошие, так и плохие слова для генерации состязательных примеров, но в среднем на передний план будут выходить слова наименьшим образом влияющие на предсказания модели.

\subsection{Параметры исследований}

\noindent\hspace{0.6cm}В качестве атакуемой модели был выбран \textbf{DistilBERT} \cite{general3}, состоящий из 6 кодировщиков, предобученный на большом корпусе текста \textbf{RuCorpora}, включающий в себя словарь из более чем 500 000 слов из разных источников и дообученный на датасетах по классификации тональности.

\noindent\hspace{0.6cm}Для лемматизации  слов использовался \textbf{Pymorphy2}, для поиска синонима из некоторой базы использовались предобученные по методу \textbf{Word2Vec} \cite{general4} вектора \textbf{RusVectors} из \textbf{Gensim} (как уже упоминалось выше, путем минимизации косинусного расстояния) и граф знаний русских слов \textbf{RuWordNet} (если граф знаний выдавал несколько синонимов, то среди них выбиралось единственное с минимальным косинусным расстоянием по отношению к исходному слову). Для обучения моделей использовался \textbf{PyTorch} и \textbf{Transformers}, для выделения отдельных слов из текста использовалась библиотека \textbf{Razdel}. Для методов интерпретации использовались готовые библиотеки: \textbf{Lime}, \textbf{Shap} и \textbf{Captum}.